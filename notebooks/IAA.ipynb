{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea5c733-d512-4bed-b643-cb0a5a01915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this is a test document made in utah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add063d2-cb64-451f-8dda-65cc9cd719e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(utah,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bda30c7e-df45-4e2e-b63e-916da8f1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"this is a test document made in utah.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20aaf660-1860-489a-a326-06347f7b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ents = doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ee93-5f7a-4a34-b610-44467c63c92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ed175-5b0c-4223-a8b7-fafe2285b6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(ent1, ent2):\n",
    "    '''calculate whether two ents overlap\n",
    "    returns bool\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(ent1, ent2):\n",
    "    '''calculate whether two ents have exact overlap\n",
    "    returns bool\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, fuzzy):\n",
    "    '''calculate the agreement betweent two docs\n",
    "       returns confusion matrix\n",
    "    '''\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for ent1 in doc1:\n",
    "        for ent2 in doc2\n",
    "            if loose:\n",
    "                if overlaps(ent1, ent2)\n",
    "                    tp++\n",
    "                else:\n",
    "                    fn++\n",
    "            else\n",
    "                exact_match\n",
    "    return (tp, fp, fn, tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(confusion matrix):\n",
    "    '''calculate f1 with given true positive, false positive, and false negative values'''\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (654967868.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [14]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i, doc1 in enumerate(docs1):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def corpus_agreement(docs1, docs2, fuzzy):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    \n",
    "    corpus_confusion_matrix = ()\n",
    "    \n",
    "    for i, doc1 in enumerate(docs1):\n",
    "        agreement(doc1, docs2[i])\n",
    "    \n",
    "    return corpus_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da80bd-9e92-4685-8984-00aef59c9719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
