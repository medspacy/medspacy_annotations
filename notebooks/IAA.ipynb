{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spacy 4 9 PERSON\n",
      "utah 37 41 GPE\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(\"Mr. Spacy is a test document made in utah.\")\n",
    "for ent in doc1.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18e248b2-be83-4214-b4ee-fd790b29993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"Mr. Spacy is a test document made in utah.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de534d63-0fa7-4878-925b-7fc279b08da3",
   "metadata": {},
   "source": [
    "Now we want to modify the name entity: 'Mr. Spacy'-> [PERSON]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mr. Spacy 0 9 PERSON\n",
      "utah 37 41 GPE\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "\n",
    "# Create a span for the new entity\n",
    "fb_ent = Span(doc2, 0, 2, label=\"PERSON\")\n",
    "orig_ents = list(doc2.ents)\n",
    "\n",
    "# Modify the provided entity spans, leaving the rest unmodified\n",
    "doc2.set_ents([fb_ent], default=\"unmodified\")\n",
    "\n",
    "for ent in doc2.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee773d9-ae4f-488e-bd43-34eddee749ba",
   "metadata": {},
   "source": [
    "# Inter Annotator Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(ent1, ent2):#compare the span \n",
    "    '''calculate whether two ents overlap\n",
    "    returns bool\n",
    "    '''\n",
    "    if ent1.start_char <= ent2.start_char and ent1.end_char > ent2.start_char:\n",
    "        return True;\n",
    "    elif ent1.start_char >= ent2.start_char and ent1.start_char<ent2.end_char:\n",
    "        return True;\n",
    "    else:\n",
    "        return False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(ent1, ent2):#compare the span \n",
    "    '''calculate whether two ents have exact overlap \n",
    "    returns bool\n",
    "    '''\n",
    "    if ent1.start_char == ent2.start_char and ent1.end_char == ent2.end_char:\n",
    "        return True;\n",
    "    else:\n",
    "        return False;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, fuzzy): #pair wise\n",
    "    '''calculate the agreement betweent two docs\n",
    "       returns confusion matrix\n",
    "    '''\n",
    "    ents1 = doc1.ents; \n",
    "    ents2 = doc2.ents;\n",
    "    \n",
    "    \n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0 #we do not have this\n",
    "    \n",
    "    if fuzzy: # span overlap\n",
    "        for ent1 in ents1:\n",
    "            findAnnot = False;\n",
    "            for ent2 in ents2:#treat ents2 as golden\n",
    "                if overlaps(ent1, ent2) and ent1.label_==ent2.label_:\n",
    "                    tp=tp+1;\n",
    "                    findAnnot = True;\n",
    "                elif overlaps(ent1, ent2) and not (ent1.label_==ent2.label_):\n",
    "                    fn=fn+1;\n",
    "                    findAnnot = True;\n",
    "            if FindAnnot==False:\n",
    "                fp=fp+1;\n",
    "    else: #exact\n",
    "        for ent1 in ents1:\n",
    "            findAnnot = False;\n",
    "            for ent2 in ents2:#treat ents2 as golden\n",
    "                if exact_match(ent1, ent2) and ent1.label_==ent2.label_:\n",
    "                    tp=tp+1;\n",
    "                    findAnnot = True;\n",
    "                elif exact_match(ent1, ent2) and not (ent1.label_==ent2.label_):\n",
    "                    fn=fn+1;\n",
    "                    findAnnot = True;\n",
    "            if FindAnnot==False:\n",
    "                fp=fp+1;\n",
    "        \n",
    "    return (tp, fp, fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(tp, fp, fn):\n",
    "    '''calculate f1 with given true positive, false positive, and false negative values'''\n",
    "    f1 = 2*tp/float(2*tp+fp+fn)\n",
    "    \n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (654967868.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [14]\u001b[0;36m\u001b[0m\n\u001b[0;31m    for i, doc1 in enumerate(docs1):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def corpus_agreement(docs1, docs2, fuzzy):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "\n",
    "    corpus_confusion_matrix = ()\n",
    "    \n",
    "    for i, doc1 in enumerate(docs1):\n",
    "        agreement(doc1, docs2[i])\n",
    "    \n",
    "    return corpus_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46da80bd-9e92-4685-8984-00aef59c9719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
