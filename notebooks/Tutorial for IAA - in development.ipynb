{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43463bee",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef71d739",
   "metadata": {},
   "source": [
    "In this tutorial I will go over the basic, front-end usage of calculating IAA between 2 annotations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02e83f2",
   "metadata": {},
   "source": [
    "## Corpus agreement between two lists of spacy documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb664d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "import pandas\n",
    "import sys\n",
    "sys.path.insert(1, './Integrated_code/')\n",
    "import IAA_ as IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4538bb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1.ents:  (utah, mississippi)\n",
      "doc2.ents:  (utah, mississippi, lake city)\n"
     ]
    }
   ],
   "source": [
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "#Note for John: Get better examples or make my own entities\n",
    "doc1 = nlp1(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "print('doc1.ents: ',doc1.ents)\n",
    "print('doc2.ents: ',doc2.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282f22a6",
   "metadata": {},
   "source": [
    "Above we made two documents using spacy's NER packages. Document 2 added more entities than document 1. Let's calculate the IAA between these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f551ab7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAA</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IAA    Recall  Precision  True Positives  False Positives  False Negative\n",
       "0  0.8  0.666667        1.0               2                1               0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IAA.corpus_agreement([doc1],[doc2])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659963fd",
   "metadata": {},
   "source": [
    "'corpus_agreement' calculates the agreement between two lists of documents, two lists containing inner lists/tuples of entities/spans, or 2 dataframes. Note the brackets around 'doc1' and 'doc2', so they are passed in as lists. This is because corpus_agreement expects lists of documents.\n",
    "\n",
    "Also note that we are selecting the first element of the returned array. This is because the code actually returns a list of 2 elements. We will look at the second element later in the tutorial under \"The returned dataframe with mappings\".\n",
    "\n",
    "Lets look at other arguments for IAA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e28bf",
   "metadata": {},
   "source": [
    "## Corpus Agreement between two dataframes\n",
    "\n",
    "*corpus_agreement* can accept two dataframes (one for each annotation set) provided they are structured correctly. Below are the default column names that the code looks for:\n",
    "\n",
    "__'start loc'__ : column containing starting positions of ents\n",
    "\n",
    "__'end loc'__ : column containing ending positions of ents\n",
    "\n",
    "__'Concept Label'__ : column containing label of ent. Only applicable if labels=1.\n",
    "\n",
    "__'doc name'__ : column containing document name/file name. The code will calculate tp,fp,fn for each document name (ie. the dataframes will be segmented based on document names, then each pair of resultant dataframes are passed along iteratively)\n",
    "\n",
    "__input attribute column names__ : This includes any column names, input through the \"attributes\" argument list (we will talk more about this below)\n",
    "\n",
    "You must use the correct dataframe column names for the code to read your dataframes. Alternatively, you can edit the default column name strings the code searches for at the top of the IAA_ code.\n",
    "\n",
    "Note that these are the same default columns created by the medspacy ereader code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa09d62",
   "metadata": {},
   "source": [
    "__Using dataframes as input is the preferred way to use *corpus_agreement*.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608620bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IAA.corpus_agreement(df1,df2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbb95e6",
   "metadata": {},
   "source": [
    "## Corpus Agreement between two lists of lists/tuples of entities/spans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6eb4e",
   "metadata": {},
   "source": [
    "You can also manually make lists of all the spans/entities in a spacy document and pass that to corpus agreement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c4a2889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAA</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IAA    Recall  Precision  True Positives  False Positives  False Negative\n",
       "0  0.8  0.666667        1.0               2                1               0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IAA.corpus_agreement([doc1.ents],[doc2.ents])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0734c74",
   "metadata": {},
   "source": [
    "Note that the corpus_agreement internally converts spacy documents into lists of the spans/entities in a document before computing the overlaps. If you do this yourself, you can directly pass the lists to the overlaps function, which will return mapping dictionaries of the entities. We'll talk about this more under 'Other functionality'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033d389",
   "metadata": {},
   "source": [
    "## Arguments for corpus_agreement\n",
    "\n",
    "'corpus_agreement' can also take other arguments to be more flexible with other IAA methods. Below are the arguments:\n",
    "\n",
    "### corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent',attributes=[ ])\n",
    "\n",
    "__docs1__: Either a list of spacy documents, list containing inner tuples/lists of entities/spans, list of spangroups, or dataframe with proper column names. Considered the golden/reference annotation for tp,fp,fn.\n",
    "    \n",
    "__docs2__: Expects the same types of inputs as docs1. Either a list of spacy documents, list of tuples/lists of entities/spans, list of spangroups, or a dataframe.\n",
    "\n",
    "__loose__: Boolean. 1 indicates to consider any overlap between entities. 0 indicates to only consider exact matches.\n",
    "\n",
    "__labels__: Boolean. 1 indicates to consider entity labels as matching criteria.\n",
    "\n",
    "__ent_or_span__: String of either 'ent' or 'span'. 'ent' indicates to compare doc.ents between documents. 'span' indicates to \n",
    "    compare doc1's only spangroup (note that doc1 must have only 1 spangroup) with doc2's equivalently named spangroup. This\n",
    "    argument is only relevant if passing in a list of spacy documents (ie. can be ignored if passing in a list of tuple/list \n",
    "    of ents/spans/spangroups or dataframe)\n",
    "    \n",
    "__attributes__: List containing column names. These columns will be compared between the two annotations as additional matching criteria. Only applies to dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f207362f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAA</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IAA    Recall  Precision  True Positives  False Positives  False Negative\n",
       "0  0.8  0.666667        1.0               2                1               0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IAA.corpus_agreement([doc1],[doc2],loose=0,labels=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fe7599",
   "metadata": {},
   "source": [
    "## The returned dataframe with mappings\n",
    "\n",
    "The second element that is returned by *corpus_agreement* is a dataframe containing relevant information on all entities between the two documents, including information on matches and matching criteria. Note that (as it stands) this functionality only works when inputing dataframes into *corpus_agreement* (this is one reason dataframes are preferred -- the other being that the attributes argument only works with dataframes).\n",
    "\n",
    "Here is an example of what this dataframe looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0090b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IAA.corpus_agreement(df1,df2,loose=1,labels=1)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66358eca",
   "metadata": {},
   "source": [
    "The dataframe returns a row for every entity included in the input dataframes. If entities match between both annotations, the relevant entities will be included in the same row. If an entity is included in one document, but not the other, the columns for the other annotation will be left blank.\n",
    "\n",
    "Here are the descriptions of the columns within this dataframe:\n",
    "\n",
    "__doc name__: Name of document from which entity(s) came from. Derived from the doc name of the input dataframe.\n",
    "\n",
    "__Annotation_1__: Entity text from annotation 1.\n",
    "\n",
    "__Annotation_2__: Entity text from annotation 2.\n",
    "\n",
    "__Annot_1_label__: The label of the entity from annotation 1.\n",
    "\n",
    "__Annot_1_char__: Character positions of annotation 1.\n",
    "\n",
    "__Annot_2_label__: The label of the entity from annotation 2.\n",
    "\n",
    "__Annot_2_char__: Character positions of annotation 2.\n",
    "\n",
    "__Overall_start_char__: The earliest starting character position between the two entities. Used to sort the entities within each document.\n",
    "\n",
    "__Exact Match?__: Boolean indicating if there is an exact match between entities starting and ending characters for matched entities within the row. (Note that this does not include exact matches of labels and attributes, unlike the case when label=0)\n",
    "\n",
    "__Duplicate Matches?__: Boolean indicate if an entity included in the row matches multiple entities of the other annotation.\n",
    "\n",
    "__Overlap?__: Boolean indicating if there is any overlap (ie. match) between entities in this row. In other words, this will be a 1 if there is at least one entity in Annotation_1 and at least one entity in Annotation_2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda6e49e",
   "metadata": {},
   "source": [
    "## Other functionality and specifics for calculation of tp,fp,fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324663f",
   "metadata": {},
   "source": [
    "Internally, corpus_agreement is figuring out what input you gave it (dataframes, lists of documents, or lists of lists/tuples of spans/entities). For lists of documents, it uses a helper function to convert the documents into lists of lists/tuples of the document's spans/entities. \n",
    "\n",
    "corpus_agreement then calls an overlap function, which returns 2 dictionaries with mappings of all matched entities/spans. These dictionaries are used to calculate the true positives, false positives, and false negatives using the 'conf_matrix' function.\n",
    "\n",
    "corpus_agreement then uses tp,fp,fn to calculate precision, recall, and f1 (using 'pairwise_f1' function).\n",
    "\n",
    "*corpus_agreement* will then call *create_agreement_df*, which uses the dictionary mappings and initial dataframes to construct the returned dataframe (containing the entity information and matches). This step only applies when dataframes were input as arguments for *corpus_agreement*.\n",
    "\n",
    "Lets try using these other functions individually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144eaf2",
   "metadata": {},
   "source": [
    "### *overlaps* for ents and span lists and *df_overlaps* for dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76edbe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: [0], 1: [1]}, {0: [0], 1: [1]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_dictionaries = IAA.overlaps(doc1.ents,doc2.ents)\n",
    "mapping_dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805dbaf3",
   "metadata": {},
   "source": [
    "### *conf_matrix* \n",
    "This uses mapping dictionaries and the amount of entities to calculate tp,fp,fn. The exact calculations used are described in a below section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fda6cd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1 0\n"
     ]
    }
   ],
   "source": [
    "tp,fp,fn = IAA.conf_matrix(mapping_dictionaries[0],mapping_dictionaries[1],len(doc1.ents),len(doc2.ents))\n",
    "print(tp,fp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68f28a",
   "metadata": {},
   "source": [
    "### *pairwise_f1*\n",
    "Finally, tp,fp,fn can be used to calculate pairwise f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00b8e836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IAA.pairwise_f1(tp,fp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d919749",
   "metadata": {},
   "source": [
    "### Calculations for true positives (tp), false positives (fp), and false negatives (fn) based on mappings\n",
    "\n",
    "Below is a description of the calculations that go into tp, fp, and fn. The high level description is given first, followed by the technical description and an example.\n",
    "\n",
    "Note that annotation 1 is considered the golden/reference standard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f94fb",
   "metadata": {},
   "source": [
    "__True Positives (tp):__\n",
    "\n",
    "<u>High level:</u> \n",
    "\n",
    "tp describes the amount of annotations in the reference standard (annotation_1) that have a match in annotation 2. This is the equivalent of the amount of keys in annotation_1's mapping dictionary, since keys are only placed in the mapping dictionary if there is a match in the other dictionary.\n",
    "\n",
    "*However*, an exception to this rule is the case where two or more entities in annotation_1 match the same entity in annotation_2. In these cases, we do not double count the \"duplicate\" matches as multiple true positives. To counteract this, we look at annotation_2's mapping dictionary for cases where an annotation in annotation_2 maps to multiple annotations in annotation_1. We use this information to subtract out the duplicated matches. In other words, if 2 or more annotations from annotation_1 maps to the same entity in annotation_2, this will only count as 1 tp, 0 fp, and 0 fn.\n",
    "\n",
    "If one entity from annotation_1 maps to several annotations in annotation_2, this also counts as 1 tp, 0 fp, and 0 fn.\n",
    "\n",
    "<u>Technical description:</u>\n",
    "\n",
    "tp = doc1_match_num - duplicate_matches\n",
    "\n",
    "where doc1_match_num is the amount (\"len()\") of keys in the mapping dictionary for annotation_1, and duplicate_matches is the sum of the lengths of all lists in annotation_2's mapping dictionary's values minus the length of keys in annotation 2's mapping dictionary. \n",
    "\n",
    "<u>Example:</u>\n",
    "\n",
    "For example, if annotation_1's mapping dictionary is \"{1: [4],2:[4],3, [9,10]}\" and is called annot1_mapping, and annot2_mapping is \"{4:[1,2],9:[3],10:[3]}\", then the length of keys in annotation_1 would be len(annot1_mapping.keys()) = 3, and annot2_mapping's values minus the length of keys would be 2 (for \"len([1,2])\") + 1 (for \"len([3])\") + 1 (for \"len([3])\") - 3 (one for each key -- \"4\", \"9\", and \"10\"), for a total of 1. Altogether, this is 3-1=2 for tp.\n",
    "\n",
    "__False Positives (fp):__\n",
    "\n",
    "<u>High level:</u>\n",
    "\n",
    "fp describes the amount of annotations in annotation_2 that did not match an annotation in annotation_1. This can be described as the total amount of annotations made in annotation_2, minus the number of annotations in annotation_2 that matched.\n",
    "\n",
    "<u>Technical Description:</u>\n",
    "\n",
    "fp = doc2_ent_num - doc2_match_num\n",
    "\n",
    "where doc2_match_num is the amount of total annotations (entities) in annotation_2, and doc2_match_num is the amount (\"len()\") of keys in the mapping dictionary for annotation_2.\n",
    "\n",
    "<u>Example:</u>\n",
    "\n",
    "If there were 10 annotations made in annotation_2, and the mapping dictionary is \"{4:[1,2],9:[3],10:[3]}\", then fp would be 10 - 3 (\"len({4:[1,2],9:[3],10:[3]})\") = 7.\n",
    "\n",
    "__False Negatives (fn):__\n",
    "\n",
    "<u>High level:</u>\n",
    "\n",
    "fn describes the amount of annotations in annotation_1 that did not match an annotation in annotation_2. This can be described as the total amount of annotations made in annotation_1, minus the amount of annotations in annotation_1 that matched.\n",
    "\n",
    "<u>Technical Description:</u>\n",
    "\n",
    "fn = doc1_ent_num - doc1_match_num\n",
    "\n",
    "where doc1_match_num is the amount of total annotations (entities) in annotation_1, and doc1_match_num is the amount (\"len()\") of keys in the mapping dictionary for annotation_1.\n",
    "\n",
    "<u>Example:</u>\n",
    "\n",
    "If there were 10 annotations made in annotation_1, and the mapping dictionary is \"{4:[1,2],9:[3],10:[3]}\", then fn would be 10 - 3 (\"len({4:[1,2],9:[3],10:[3]})\") = 7."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8]",
   "language": "python",
   "name": "conda-env-python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
