{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb0fb6",
   "metadata": {},
   "source": [
    "# Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ce3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5c733-d512-4bed-b643-cb0a5a01915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add063d2-cb64-451f-8dda-65cc9cd719e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda30c7e-df45-4e2e-b63e-916da8f1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf660-1860-489a-a326-06347f7b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ee93-5f7a-4a34-b610-44467c63c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13836407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run below cells before this\n",
    "tp,fp,fn = agreement(doc,doc2,1,1)\n",
    "print(tp,fp,fn)\n",
    "print(pairwise_f1(tp,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102f0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66da284",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "test_str = \"This is a test document. For testing lol.\"\n",
    "test_str_2 = \"This is a test document. For testing lol.\"\n",
    "\n",
    "doc = nlp(test_str)\n",
    "doc2 = nlp(test_str)\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[0:1], doc[1:3]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc.spans[\"entity\"] = group\n",
    "\n",
    "\n",
    "spans = [doc2[0:1], doc2[1:5],doc2[4:5]]\n",
    "group = SpanGroup(doc2, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc2.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc2, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc2.spans[\"entity\"] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e55ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Error: Input must be iterable of spacy documents, or dataframe.\n"
     ]
    }
   ],
   "source": [
    "IAA.corpus_agreement([doc.spans['errors']],doc.ents,labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4725109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a test', 'PERSON'), ('utah', 'GPE'), ('mississippi', 'PERSON'), ('lake', 'GPE'), ('city', 'GPE')]\n",
      "[utah, or mississippi]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[7:8], doc[8:10]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "print(doc.spans['errors'])\n",
    "print(doc.spans['errors'][0].label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.spans['errors'])\n",
    "for span in doc.spans['errors']:\n",
    "    print('what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5026449",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc.ents,doc.spans['errors'],labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc,doc2,ent_or_span='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc.ents[0]) is spacy.tokens.span.Span\n",
    "type(doc.spans['errors']) is spacy.tokens.span_group.SpanGroup\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098164e2",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def overlaps(doc1_ents, doc2_ents,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        tree.add(ent2.start_char,ent2.end_char,index2)\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        matches = tree.search(ent1.start_char,ent1.end_char)\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (doc2_ents[index2].label_ == ent1.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the old, less efficient code. The newer code uses a tree search instead of the nested for-loop.\n",
    "\n",
    "def old_overlaps(doc1_ents, doc2_ents,labels):\n",
    "    '''Old code for calculating overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        for index2,ent2 in enumerate(doc2_ents):\n",
    "            if (ent1.end_char >= ent2.start_char) & (ent1.start_char <= ent2.end_char) & ((labels==0) | (ent1.label_ == ent2.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(doc1_ents, doc2_ents, labels):\n",
    "    '''calculate whether two ents have exact overlap\n",
    "    returns bool\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    doc1_ent_dict = dict()\n",
    "    doc2_ent_dict = dict()\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        if labels == 1: #If checking for labels, then include this in the tuple's to-be-compared elements\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char,ent1.label_)] = index1\n",
    "        else:\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char)] = index1\n",
    "            \n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        if labels == 1:    \n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char,ent2.label_)] = index2\n",
    "        else:\n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char)] = index2\n",
    "        \n",
    "    doc1_ent_set = set(doc1_ent_dict.keys())\n",
    "    doc2_ent_set = set(doc2_ent_dict.keys())\n",
    "    \n",
    "    matched_ents = doc1_ent_set.intersection(doc2_ent_set)\n",
    "    \n",
    "    for match in matched_ents:\n",
    "        index1 = doc1_ent_dict[match]\n",
    "        index2 = doc2_ent_dict[match]\n",
    "        doc1_matches[index1] = [index2]\n",
    "        doc2_matches[index2] = [index1]\n",
    "        \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, loose=1, labels=1, ent_or_span = 'ent'):\n",
    "    '''Calculates confusion matrix for agreement between two documents.\n",
    "    \n",
    "       returns true positive, false positive, and false negative\n",
    "    '''\n",
    "    if (type(doc1) is tuple) or (type(doc1) is spacy.tokens.span_group.SpanGroup) and \\\n",
    "    (type(doc2) is tuple) or (type(doc2) is spacy.tokens.span_group.SpanGroup):\n",
    "        doc1_ents = doc1\n",
    "        doc2_ents = doc2\n",
    "    elif (type(doc1) is spacy.tokens.doc.Doc) and (type(doc2) is spacy.tokens.doc.Doc):\n",
    "        if ent_or_span == 'ent':\n",
    "            doc1_ents = doc1.ents\n",
    "            doc2_ents = doc2.ents\n",
    "        elif ent_or_span == 'span':\n",
    "            if len(doc1.spans) > 1:\n",
    "                #raise error\n",
    "                print(\"Error: cannot distinquish which span group to use from doc1.\")\n",
    "                return\n",
    "            else:\n",
    "                span_group = list(doc1.spans.keys())[0]\n",
    "                doc1_ents = doc1.spans[span_group]\n",
    "                doc2_ents = doc2.spans[span_group]\n",
    "        else:\n",
    "            #raise error\n",
    "            print(\"Error: Must select 'span' or 'ent' for ent_or_span option.\")\n",
    "            return\n",
    "    else:\n",
    "        #raise error\n",
    "        print(\"Error: Input must be of type 'tuples', 'spacy.tokens.span_group.SpanGroup', or 'spacy.tokens.doc.Doc'\")\n",
    "        return\n",
    "        \n",
    "    if loose:\n",
    "        doc1_matches, doc2_matches = overlaps(doc1_ents, doc2_ents, labels)\n",
    "    else:\n",
    "        doc1_matches, doc2_matches = exact_match(doc1_ents, doc2_ents, labels)\n",
    "    \n",
    "    return conf_matrix(doc1_matches,doc2_matches,len(doc1_ents),len(doc2_ents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(doc1_matches,doc2_matches,doc1_ent_num,doc2_ent_num):\n",
    "\n",
    "    doc1_match_num = len(doc1_matches.keys())\n",
    "    doc2_match_num = len(doc2_matches.keys())\n",
    "    \n",
    "    duplicate_matches = 0\n",
    "    for value in doc2_matches.values():\n",
    "        duplicate_matches += len(value) - 1\n",
    "    \n",
    "    tp = doc1_match_num - duplicate_matches #How many entity indices from doc1 matched, minus duplicated matches\n",
    "    fp = doc2_ent_num - doc2_match_num #How many entities from doc2 that didn't match\n",
    "    fn = doc1_ent_num - doc1_match_num #How many entities from doc1 that didn't match\n",
    "    \n",
    "    return (tp,fp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(tp,fp,fn):\n",
    "    '''calculate f1 given true positive, false positive, and false negative values'''\n",
    "    \n",
    "    return (2*tp)/float(2*tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    if type(docs1[0]) is spacy.tokens.doc.Doc:\n",
    "        for i, doc1 in enumerate(docs1):\n",
    "            tp,fp,fn = agreement(doc1, docs2[i],loose,labels,ent_or_span)\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    elif type(docs1) is pandas.core.frame.DataFrame:\n",
    "        for doc_name in docs1['doc name'].unique():\n",
    "            docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "            docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "            doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "            tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    else:\n",
    "        #raise error\n",
    "        print('Input Error: Input must be iterable of spacy documents, or dataframe.')\n",
    "        return\n",
    "    \n",
    "    data = {'IAA' : [pairwise_f1(corpus_tp,corpus_fp,corpus_fn)], 'Recall' : [tp/float(tp+fp)], 'Precision' : [tp/float(tp+fn)],\\\n",
    "           'True Positives' : [tp] , 'False Positives' : [fp], 'False Negative' : [fn]}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659aa61",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b1907",
   "metadata": {},
   "source": [
    "In this tutorial I will go over the basic, front-end usage of calculating IAA between 2 annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "#Note for John: Get better examples or make my own entities\n",
    "doc1 = nlp1(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "print('doc1.ents: ',doc1.ents)\n",
    "print('doc2.ents: ',doc2.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9bda4",
   "metadata": {},
   "source": [
    "Above we made two documents using spacy's NER packages. Document 2 added more entities than document 1. Let's calculate the IAA between these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_agreement([doc1],[doc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deef70",
   "metadata": {},
   "source": [
    "'corpus_agreement' calculates the agreement between two lists of documents. Note the brackets around 'doc1' and 'doc2' so they are passed in as lists of size 1 each.\n",
    "\n",
    "'corpus_agreement' can also take options to be more flexible with other IAA methods. Below are the arguments:\n",
    "\n",
    "### corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent')\n",
    "\n",
    "docs1: list of spacy documents\n",
    "\n",
    "docs2: list of spacy documents with same order as docs1\n",
    "\n",
    "loose: Boolean for allowing loose matching. '1' indicates that any overlap between two spans/entities is counted towards IAA. '0' indicates that only exact matches will be allowed.\n",
    "\n",
    "labels: Boolean to include labels when matching. Uses the .label_ attribute of entities/spans to access labels.\n",
    "\n",
    "ent_or_span: string of whether spans or entities are being compared. If set to 'ent', code will iterate through doc1.ents and doc2.ents. If set to 'span', code will iterate through the spans within doc1 and doc2's first span group. 'span' only works if doc1 has one span group. This option may be extended to include doc._ .concepts option, or to allow multiple span groups to be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cd59c",
   "metadata": {},
   "source": [
    "Internally, corpus_agreement is calling the 'agreement' and 'pairwise_f1' functions on each pair of document in the lists. We can instead choose to call these functions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efb4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e03665",
   "metadata": {},
   "source": [
    "# Code in Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "john_df = pd.read_pickle('./df_John.pkl')\n",
    "#john_df = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df = pd.read_pickle('./df_Mengke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c205740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def df_overlaps(docs1_df, docs2_df,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,row2 in docs2_df.iterrows():\n",
    "        tree.add(row2['start loc'],row2['end loc'],index2)\n",
    "    \n",
    "    for index1,row1 in docs1_df.iterrows():\n",
    "        matches = tree.search(row1['start loc'],row1['end loc'])\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (docs2_df.loc[index2,'Concept Label'] == row1['Concept Label'])):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    for doc_name in docs1['doc name'].unique():\n",
    "        docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "        docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "        doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "        tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "        corpus_tp += tp\n",
    "        corpus_fp += fp\n",
    "        corpus_fn += fn\n",
    "    \n",
    "    print('corpus tp: ',corpus_tp,'\\ncorpus fp: ',corpus_fp,'\\ncorpus fn: ',corpus_fn)\n",
    "    \n",
    "    print(tp)\n",
    "    print(corpus_tp)\n",
    "    \n",
    "    #print(\"Not in doc2 annotations:\\n\")\n",
    "    for index,row in docs1.iterrows():\n",
    "        if (index not in doc2_matches.keys()):\n",
    "            #print(row['Span Text'])\n",
    "            break\n",
    "    \n",
    "    return pairwise_f1(corpus_tp,corpus_fp,corpus_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d477f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_agreement(john_df,mengke_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b296aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "john_df_symptoms = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df_symptoms = mengke_df[mengke_df['Concept Label'] == 'Symptom']\n",
    "\n",
    "df_corpus_agreement(john_df_symptoms,mengke_df_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_agreement(john_df_symptoms,mengke_df_symptoms,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3f8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(john_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6de8125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, './Integrated_code/')\n",
    "import IAA_ as IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c02654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "john_df = pd.read_pickle('./df_John.pkl')\n",
    "#john_df = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df = pd.read_pickle('./df_Mengke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ab88610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485939.txt\n",
      "366026.txt\n",
      "5585.txt\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mIAA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorpus_agreement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjohn_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmengke_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\Desktop\\work forms filled\\projects\\medspacy_annotations\\notebooks\\./Integrated_code\\IAA_.py:252\u001b[0m, in \u001b[0;36mcorpus_agreement\u001b[1;34m(docs1, docs2, loose, labels, ent_or_span)\u001b[0m\n\u001b[0;32m    250\u001b[0m         corpus_fp \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m    251\u001b[0m         corpus_fn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m fn\n\u001b[1;32m--> 252\u001b[0m         agreement_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([agreement_df,\u001b[43mcreate_agreement_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc1_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdoc2_matches\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdocs1_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdocs2_df\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\u001b[38;5;28mtype\u001b[39m(docs1[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m spacy\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mDoc) \u001b[38;5;241m|\u001b[39m ((\u001b[38;5;28misinstance\u001b[39m(docs1[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(docs1[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(docs1[\u001b[38;5;241m0\u001b[39m],spacy\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mspan_group\u001b[38;5;241m.\u001b[39mSpanGroup)) \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    256\u001b[0m (\u001b[38;5;28misinstance\u001b[39m(docs2[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(docs2[\u001b[38;5;241m0\u001b[39m],\u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(docs2[\u001b[38;5;241m0\u001b[39m],spacy\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mspan_group\u001b[38;5;241m.\u001b[39mSpanGroup)))):\n\u001b[0;32m    257\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, doc1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(docs1):\n",
      "File \u001b[1;32m~\\Desktop\\work forms filled\\projects\\medspacy_annotations\\notebooks\\./Integrated_code\\IAA_.py:335\u001b[0m, in \u001b[0;36mcreate_agreement_df\u001b[1;34m(doc1_matches, doc2_matches, doc1_ents, doc2_ents)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_index1 \u001b[38;5;241m<\u001b[39m index1:\n\u001b[0;32m    333\u001b[0m     \u001b[38;5;66;03m#Add to index: sorted(doc2_matches[first_index2])[0]\u001b[39;00m\n\u001b[0;32m    334\u001b[0m     duplicate_match_index \u001b[38;5;241m=\u001b[39m result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(first_index1)\n\u001b[1;32m--> 335\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnotation_1\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m || \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m doc1_ents\u001b[38;5;241m.\u001b[39mloc[index1,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpan Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    336\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate Matches?\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    337\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverlap?\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "IAA.corpus_agreement(john_df,mengke_df,labels=0)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0290fea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['485939.txt', '366026.txt', '5585.txt', '669731.txt', '33200.txt',\n",
       "       '36609.txt', '335643.txt', '52374.txt', '38580.txt', '601884.txt',\n",
       "       '38757.txt', '416614.txt', '45725.txt', '56773.txt', '19070.txt',\n",
       "       '628045.txt', '45509.txt', '527735.txt', '439912.txt',\n",
       "       '457012.txt', '595179.txt', '575514.txt', '28056.txt',\n",
       "       '655523.txt', '537108.txt', '33137.txt', '330814.txt', '18826.txt',\n",
       "       '700062.txt', '26272.txt', '321062.txt', '584041.txt',\n",
       "       '369557.txt', '679566.txt', '593885.txt', '379.txt', '489228.txt',\n",
       "       '24881.txt', '377554.txt', '700799.txt', '26388.txt', '330335.txt',\n",
       "       '18305.txt', '375911.txt', '345622.txt', '346854.txt',\n",
       "       '536291.txt', '456788.txt', '5749.txt', '3271.txt'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df['doc name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c02aeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Span Text</th>\n",
       "      <th>Concept Label</th>\n",
       "      <th>start loc</th>\n",
       "      <th>end loc</th>\n",
       "      <th>doc name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Left chest pain and left sided weakness</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>154</td>\n",
       "      <td>194</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>chest pain and left arm weakness. The chest pain</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>390</td>\n",
       "      <td>438</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>denies dyspnea, visual changes, loss\\nof consc...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>1224</td>\n",
       "      <td>1317</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Left chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>155</td>\n",
       "      <td>170</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>left sided weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>175</td>\n",
       "      <td>194</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>390</td>\n",
       "      <td>400</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>405</td>\n",
       "      <td>422</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>428</td>\n",
       "      <td>438</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>radiating pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>526</td>\n",
       "      <td>540</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>596</td>\n",
       "      <td>613</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>656</td>\n",
       "      <td>673</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>episode</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>934</td>\n",
       "      <td>941</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>episode</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1047</td>\n",
       "      <td>1054</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1098</td>\n",
       "      <td>1102</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1104</td>\n",
       "      <td>1112</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>paresthesias</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1117</td>\n",
       "      <td>1129</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>residual diminished\\nsensation</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1181</td>\n",
       "      <td>1210</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>dyspnea</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1231</td>\n",
       "      <td>1238</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>visual changes</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1240</td>\n",
       "      <td>1254</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>loss\\nof consciousness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1256</td>\n",
       "      <td>1277</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>aphasia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1279</td>\n",
       "      <td>1286</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>hematuria</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1288</td>\n",
       "      <td>1297</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>dysuria</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1299</td>\n",
       "      <td>1306</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>neck pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1308</td>\n",
       "      <td>1317</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>peripheral polyneuropathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5903</td>\n",
       "      <td>5928</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>transient ischemic</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8289</td>\n",
       "      <td>8307</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>obesity</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8496</td>\n",
       "      <td>8503</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>hyperlipidemia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8552</td>\n",
       "      <td>8566</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Span Text  \\\n",
       "17                                                  :   \n",
       "18            Left chest pain and left sided weakness   \n",
       "19   chest pain and left arm weakness. The chest pain   \n",
       "20  denies dyspnea, visual changes, loss\\nof consc...   \n",
       "21                                    Left chest pain   \n",
       "22                                left sided weakness   \n",
       "23                                         chest pain   \n",
       "24                                  left arm weakness   \n",
       "25                                         chest pain   \n",
       "26                                     radiating pain   \n",
       "27                                  left arm weakness   \n",
       "28                                  left arm weakness   \n",
       "29                                            episode   \n",
       "30                                            episode   \n",
       "31                                               pain   \n",
       "32                                           weakness   \n",
       "33                                       paresthesias   \n",
       "34                     residual diminished\\nsensation   \n",
       "35                                            dyspnea   \n",
       "36                                     visual changes   \n",
       "37                             loss\\nof consciousness   \n",
       "38                                            aphasia   \n",
       "39                                          hematuria   \n",
       "40                                            dysuria   \n",
       "41                                          neck pain   \n",
       "42                          peripheral polyneuropathy   \n",
       "43                                 transient ischemic   \n",
       "44                                            obesity   \n",
       "45                                     hyperlipidemia   \n",
       "\n",
       "               Concept Label  start loc  end loc  doc name  \n",
       "17  SectionHeader_HasSymptom        152      153  5585.txt  \n",
       "18           Symptom_Section        154      194  5585.txt  \n",
       "19           Symptom_Section        390      438  5585.txt  \n",
       "20           Symptom_Section       1224     1317  5585.txt  \n",
       "21                   Symptom        155      170  5585.txt  \n",
       "22                   Symptom        175      194  5585.txt  \n",
       "23                   Symptom        390      400  5585.txt  \n",
       "24                   Symptom        405      422  5585.txt  \n",
       "25                   Symptom        428      438  5585.txt  \n",
       "26                   Symptom        526      540  5585.txt  \n",
       "27                   Symptom        596      613  5585.txt  \n",
       "28                   Symptom        656      673  5585.txt  \n",
       "29                   Symptom        934      941  5585.txt  \n",
       "30                   Symptom       1047     1054  5585.txt  \n",
       "31                   Symptom       1098     1102  5585.txt  \n",
       "32                   Symptom       1104     1112  5585.txt  \n",
       "33                   Symptom       1117     1129  5585.txt  \n",
       "34                   Symptom       1181     1210  5585.txt  \n",
       "35                   Symptom       1231     1238  5585.txt  \n",
       "36                   Symptom       1240     1254  5585.txt  \n",
       "37                   Symptom       1256     1277  5585.txt  \n",
       "38                   Symptom       1279     1286  5585.txt  \n",
       "39                   Symptom       1288     1297  5585.txt  \n",
       "40                   Symptom       1299     1306  5585.txt  \n",
       "41                   Symptom       1308     1317  5585.txt  \n",
       "42                   Symptom       5903     5928  5585.txt  \n",
       "43                   Symptom       8289     8307  5585.txt  \n",
       "44                   Symptom       8496     8503  5585.txt  \n",
       "45                   Symptom       8552     8566  5585.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df_doc1 = john_df[john_df['doc name'] == '5585.txt']\n",
    "mengke_df_doc1 = mengke_df[mengke_df['doc name'] == '5585.txt']\n",
    "mengke_df_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdf27592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Span Text</th>\n",
       "      <th>Concept Label</th>\n",
       "      <th>start loc</th>\n",
       "      <th>end loc</th>\n",
       "      <th>doc name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Left chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>155</td>\n",
       "      <td>170</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>left sided weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>175</td>\n",
       "      <td>194</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>390</td>\n",
       "      <td>400</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>405</td>\n",
       "      <td>422</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>chest pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>428</td>\n",
       "      <td>438</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>596</td>\n",
       "      <td>613</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>left arm weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>656</td>\n",
       "      <td>673</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1098</td>\n",
       "      <td>1102</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1104</td>\n",
       "      <td>1112</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>paresthesias of the left face</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1117</td>\n",
       "      <td>1146</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>upper and lower extremities with residual dimi...</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1148</td>\n",
       "      <td>1210</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>dyspnea</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1231</td>\n",
       "      <td>1238</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>visual changes</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1240</td>\n",
       "      <td>1254</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>loss\\nof consciousness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1256</td>\n",
       "      <td>1277</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>aphasia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1279</td>\n",
       "      <td>1286</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>hematuria</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1288</td>\n",
       "      <td>1297</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>dysuria</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1299</td>\n",
       "      <td>1306</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>neck pain</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1308</td>\n",
       "      <td>1317</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>obesity</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1813</td>\n",
       "      <td>1820</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>depression</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1960</td>\n",
       "      <td>1970</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Obese</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>2711</td>\n",
       "      <td>2716</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>carotid bruits</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>2879</td>\n",
       "      <td>2893</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>jugular venous\\ndistension</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>2898</td>\n",
       "      <td>2923</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>lymphadenopathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>2928</td>\n",
       "      <td>2943</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>obese</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>3109</td>\n",
       "      <td>3114</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>left\\nventricular hypertrophy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4032</td>\n",
       "      <td>4060</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>dysarthria</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4612</td>\n",
       "      <td>4622</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>apraxia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4637</td>\n",
       "      <td>4644</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>agnosia</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4646</td>\n",
       "      <td>4653</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>neglect</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4658</td>\n",
       "      <td>4665</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>left to\\nright mismatch</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4689</td>\n",
       "      <td>4711</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>decreased vibration at the toes</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4893</td>\n",
       "      <td>4924</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>wasting of the\\nthenar muscles on the left</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4976</td>\n",
       "      <td>5017</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>bilateral EDBs</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5022</td>\n",
       "      <td>5036</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>fasciculations</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5078</td>\n",
       "      <td>5092</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>adventitious movements</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5115</td>\n",
       "      <td>5137</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>asterixis</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5141</td>\n",
       "      <td>5150</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Reflexes absent, biceps,\\nbrachials, triceps</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5372</td>\n",
       "      <td>5415</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>left sided weakness</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5796</td>\n",
       "      <td>5815</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>peripheral polyneuropathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>5903</td>\n",
       "      <td>5928</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>dysrhythmias</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>6152</td>\n",
       "      <td>6164</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>renal\\ninsufficiencies</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>6981</td>\n",
       "      <td>7002</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>renal insufficiency</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>7028</td>\n",
       "      <td>7047</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>diabetic nephropathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>7063</td>\n",
       "      <td>7083</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>headache</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>7980</td>\n",
       "      <td>7988</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>ischemic attacks</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8299</td>\n",
       "      <td>8315</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>renal\\ninsufficiency</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8410</td>\n",
       "      <td>8429</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>nephropathy</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8472</td>\n",
       "      <td>8483</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>obesity</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>8496</td>\n",
       "      <td>8503</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>HISTORY OF PRESENT ILLNESS:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>197</td>\n",
       "      <td>224</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>PAST MEDICAL HISTORY:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>1610</td>\n",
       "      <td>1631</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PHYSICAL EXAMINATION:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>2568</td>\n",
       "      <td>2589</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>HOSPITAL COURSE:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>3416</td>\n",
       "      <td>3432</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>DISCHARGE DIAGNOSES:</td>\n",
       "      <td>SectionHeader_HasSymptom</td>\n",
       "      <td>8225</td>\n",
       "      <td>8245</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>This is a 57 year-old female\\nwith diabetes, h...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>226</td>\n",
       "      <td>1610</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Chronic renal insufficiency with a\\nbaseline c...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>1633</td>\n",
       "      <td>2033</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Vital signs: 98.9, 60, 16, blood\\npressure 156...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>2591</td>\n",
       "      <td>3414</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>The patient was initially evaluated in the\\nem...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>3434</td>\n",
       "      <td>8223</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Carotid artery stenosis with a history\\nof tra...</td>\n",
       "      <td>Symptom_Section</td>\n",
       "      <td>8247</td>\n",
       "      <td>8690</td>\n",
       "      <td>5585.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Span Text  \\\n",
       "30                                    Left chest pain   \n",
       "31                                left sided weakness   \n",
       "32                                         chest pain   \n",
       "33                                  left arm weakness   \n",
       "34                                         chest pain   \n",
       "35                                  left arm weakness   \n",
       "36                                  left arm weakness   \n",
       "37                                               pain   \n",
       "38                                           weakness   \n",
       "39                      paresthesias of the left face   \n",
       "40  upper and lower extremities with residual dimi...   \n",
       "41                                            dyspnea   \n",
       "42                                     visual changes   \n",
       "43                             loss\\nof consciousness   \n",
       "44                                            aphasia   \n",
       "45                                          hematuria   \n",
       "46                                            dysuria   \n",
       "47                                          neck pain   \n",
       "48                                            obesity   \n",
       "49                                         depression   \n",
       "50                                              Obese   \n",
       "51                                     carotid bruits   \n",
       "52                         jugular venous\\ndistension   \n",
       "53                                    lymphadenopathy   \n",
       "54                                              obese   \n",
       "55                      left\\nventricular hypertrophy   \n",
       "56                                         dysarthria   \n",
       "57                                            apraxia   \n",
       "58                                            agnosia   \n",
       "59                                            neglect   \n",
       "60                            left to\\nright mismatch   \n",
       "61                    decreased vibration at the toes   \n",
       "62         wasting of the\\nthenar muscles on the left   \n",
       "63                                     bilateral EDBs   \n",
       "64                                     fasciculations   \n",
       "65                             adventitious movements   \n",
       "66                                          asterixis   \n",
       "67       Reflexes absent, biceps,\\nbrachials, triceps   \n",
       "68                                left sided weakness   \n",
       "69                          peripheral polyneuropathy   \n",
       "70                                       dysrhythmias   \n",
       "71                             renal\\ninsufficiencies   \n",
       "72                                renal insufficiency   \n",
       "73                               diabetic nephropathy   \n",
       "74                                           headache   \n",
       "75                                   ischemic attacks   \n",
       "76                               renal\\ninsufficiency   \n",
       "77                                        nephropathy   \n",
       "78                                            obesity   \n",
       "79                        HISTORY OF PRESENT ILLNESS:   \n",
       "80                              PAST MEDICAL HISTORY:   \n",
       "81                              PHYSICAL EXAMINATION:   \n",
       "82                                   HOSPITAL COURSE:   \n",
       "83                               DISCHARGE DIAGNOSES:   \n",
       "84  This is a 57 year-old female\\nwith diabetes, h...   \n",
       "85  Chronic renal insufficiency with a\\nbaseline c...   \n",
       "86  Vital signs: 98.9, 60, 16, blood\\npressure 156...   \n",
       "87  The patient was initially evaluated in the\\nem...   \n",
       "88  Carotid artery stenosis with a history\\nof tra...   \n",
       "\n",
       "               Concept Label  start loc  end loc  doc name  \n",
       "30                   Symptom        155      170  5585.txt  \n",
       "31                   Symptom        175      194  5585.txt  \n",
       "32                   Symptom        390      400  5585.txt  \n",
       "33                   Symptom        405      422  5585.txt  \n",
       "34                   Symptom        428      438  5585.txt  \n",
       "35                   Symptom        596      613  5585.txt  \n",
       "36                   Symptom        656      673  5585.txt  \n",
       "37                   Symptom       1098     1102  5585.txt  \n",
       "38                   Symptom       1104     1112  5585.txt  \n",
       "39                   Symptom       1117     1146  5585.txt  \n",
       "40                   Symptom       1148     1210  5585.txt  \n",
       "41                   Symptom       1231     1238  5585.txt  \n",
       "42                   Symptom       1240     1254  5585.txt  \n",
       "43                   Symptom       1256     1277  5585.txt  \n",
       "44                   Symptom       1279     1286  5585.txt  \n",
       "45                   Symptom       1288     1297  5585.txt  \n",
       "46                   Symptom       1299     1306  5585.txt  \n",
       "47                   Symptom       1308     1317  5585.txt  \n",
       "48                   Symptom       1813     1820  5585.txt  \n",
       "49                   Symptom       1960     1970  5585.txt  \n",
       "50                   Symptom       2711     2716  5585.txt  \n",
       "51                   Symptom       2879     2893  5585.txt  \n",
       "52                   Symptom       2898     2923  5585.txt  \n",
       "53                   Symptom       2928     2943  5585.txt  \n",
       "54                   Symptom       3109     3114  5585.txt  \n",
       "55                   Symptom       4032     4060  5585.txt  \n",
       "56                   Symptom       4612     4622  5585.txt  \n",
       "57                   Symptom       4637     4644  5585.txt  \n",
       "58                   Symptom       4646     4653  5585.txt  \n",
       "59                   Symptom       4658     4665  5585.txt  \n",
       "60                   Symptom       4689     4711  5585.txt  \n",
       "61                   Symptom       4893     4924  5585.txt  \n",
       "62                   Symptom       4976     5017  5585.txt  \n",
       "63                   Symptom       5022     5036  5585.txt  \n",
       "64                   Symptom       5078     5092  5585.txt  \n",
       "65                   Symptom       5115     5137  5585.txt  \n",
       "66                   Symptom       5141     5150  5585.txt  \n",
       "67                   Symptom       5372     5415  5585.txt  \n",
       "68                   Symptom       5796     5815  5585.txt  \n",
       "69                   Symptom       5903     5928  5585.txt  \n",
       "70                   Symptom       6152     6164  5585.txt  \n",
       "71                   Symptom       6981     7002  5585.txt  \n",
       "72                   Symptom       7028     7047  5585.txt  \n",
       "73                   Symptom       7063     7083  5585.txt  \n",
       "74                   Symptom       7980     7988  5585.txt  \n",
       "75                   Symptom       8299     8315  5585.txt  \n",
       "76                   Symptom       8410     8429  5585.txt  \n",
       "77                   Symptom       8472     8483  5585.txt  \n",
       "78                   Symptom       8496     8503  5585.txt  \n",
       "79  SectionHeader_HasSymptom        197      224  5585.txt  \n",
       "80  SectionHeader_HasSymptom       1610     1631  5585.txt  \n",
       "81  SectionHeader_HasSymptom       2568     2589  5585.txt  \n",
       "82  SectionHeader_HasSymptom       3416     3432  5585.txt  \n",
       "83  SectionHeader_HasSymptom       8225     8245  5585.txt  \n",
       "84           Symptom_Section        226     1610  5585.txt  \n",
       "85           Symptom_Section       1633     2033  5585.txt  \n",
       "86           Symptom_Section       2591     3414  5585.txt  \n",
       "87           Symptom_Section       3434     8223  5585.txt  \n",
       "88           Symptom_Section       8247     8690  5585.txt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "478f8921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({30: [21, 18],\n",
       "  31: [18, 22],\n",
       "  32: [19, 23],\n",
       "  33: [19, 24],\n",
       "  34: [19, 25],\n",
       "  35: [27],\n",
       "  36: [28],\n",
       "  37: [31],\n",
       "  38: [32],\n",
       "  39: [33],\n",
       "  40: [34],\n",
       "  41: [20, 35],\n",
       "  42: [20, 36],\n",
       "  43: [20, 37],\n",
       "  44: [20, 38],\n",
       "  45: [20, 39],\n",
       "  46: [20, 40],\n",
       "  47: [20, 41],\n",
       "  69: [42],\n",
       "  75: [43],\n",
       "  78: [44],\n",
       "  84: [28,\n",
       "   19,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   20,\n",
       "   34,\n",
       "   29,\n",
       "   30,\n",
       "   31,\n",
       "   32,\n",
       "   33,\n",
       "   35,\n",
       "   36,\n",
       "   37,\n",
       "   39,\n",
       "   38,\n",
       "   40,\n",
       "   41],\n",
       "  87: [42],\n",
       "  88: [44, 43, 45]},\n",
       " {21: [30],\n",
       "  18: [30, 31],\n",
       "  22: [31],\n",
       "  19: [32, 33, 34, 84],\n",
       "  23: [32, 84],\n",
       "  24: [33, 84],\n",
       "  25: [34, 84],\n",
       "  27: [35, 84],\n",
       "  28: [36, 84],\n",
       "  31: [37, 84],\n",
       "  32: [38, 84],\n",
       "  33: [39, 84],\n",
       "  34: [40, 84],\n",
       "  20: [41, 42, 43, 44, 45, 46, 47, 84],\n",
       "  35: [41, 84],\n",
       "  36: [42, 84],\n",
       "  37: [43, 84],\n",
       "  38: [44, 84],\n",
       "  39: [45, 84],\n",
       "  40: [46, 84],\n",
       "  41: [47, 84],\n",
       "  42: [69, 87],\n",
       "  43: [75, 88],\n",
       "  44: [78, 88],\n",
       "  26: [84],\n",
       "  29: [84],\n",
       "  30: [84],\n",
       "  45: [88]})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = IAA.df_overlaps(john_df_doc1,mengke_df_doc1,labels=0)\n",
    "dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6be92d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5585.txt\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mIAA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_agreement_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdicts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdicts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mjohn_df_doc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmengke_df_doc1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Desktop\\work forms filled\\projects\\medspacy_annotations\\notebooks\\./Integrated_code\\IAA_.py:336\u001b[0m, in \u001b[0;36mcreate_agreement_df\u001b[1;34m(doc1_matches, doc2_matches, doc1_ents, doc2_ents)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_index1 \u001b[38;5;241m<\u001b[39m index1:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;66;03m#Add to index: sorted(doc2_matches[first_index2])[0]\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     duplicate_match_index \u001b[38;5;241m=\u001b[39m result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex(first_index1)\n\u001b[1;32m--> 336\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnnotation_1\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m || \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m doc1_ents\u001b[38;5;241m.\u001b[39mloc[index1,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpan Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    337\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate Matches?\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    338\u001b[0m     result_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOverlap?\u001b[39m\u001b[38;5;124m\"\u001b[39m][duplicate_match_index] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "IAA.create_agreement_df(dicts[0],dicts[1],john_df_doc1,mengke_df_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "655a3507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test1': [6, 5, 6]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = {\"Test1\" : [4,5,6]}\n",
    "test_dict[\"Test1\"][0] += 2\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dae15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This was a very bad idea\n",
    "\n",
    "def match_indices_recursive(doc1_matches,doc2_matches,index,doc1_doc2,doc1_indices,doc2_indices):  \n",
    "    if (doc1_doc2==1):\n",
    "        doc1_indices.add(index)\n",
    "        for index2 in doc1_matches[index]:\n",
    "            if index2 not in doc2_indices():\n",
    "                doc2_indices.add(index2)\n",
    "                doc2_indices.add(match_indices_recursive(doc1_matches,doc2_matches,index2,2,doc1_indices,doc2_indices))\n",
    "    elif doc1_doc2==2:\n",
    "        doc2_indices.add(index)\n",
    "        for index1 in doc2_matches[index]:\n",
    "            return (match_indices_recursive(doc1_matches,doc2_matches,index2,1,doc1_indices,doc2_indices)[0].add(index1))\n",
    "    else:\n",
    "        return [set(),set()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "714ac1fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test</th>\n",
       "      <th>test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  test test2\n",
       "0    2     3\n",
       "1    3     4"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(columns=['test','test2'])\n",
    "test2 = pd.DataFrame({'test': [2,3], 'test2' : [3,4]})\n",
    "pd.concat([test,test2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d46b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agreement_df(doc1_matches,doc2_matches,doc1_ents,doc2_ents):\n",
    "    result_dict = {\"Index\" : [],\"Annotation_1\" : [],\"Annotation_2\" : [], \"Exact Match?\" : [], \"Duplicate Matches?\" : [], \"Overlap?\" : []} \n",
    "    \n",
    "    #Add doc name,labels,start_char(1&2),end_char(1&2), fix index, get rid of index column\n",
    "    \n",
    "    for index1 in range(doc1_ents.shape[0]): #iterate through all ents inset one\n",
    "        if index1 in doc1_matches.keys(): #if ent is in\n",
    "            #if another index1 is in doc2_matches.values(), then add it to this row\n",
    "            first_index2 = sorted(doc1_matches[index1])[0]\n",
    "            first_index1 = sorted(doc2_matches[first_index2])[0]\n",
    "            if first_index1 < index1:\n",
    "                #Add to index: sorted(doc2_matches[first_index2])[0]\n",
    "                duplicate_match_index = result_dict[\"Index\"].index(first_index1)\n",
    "                result_dict[\"Index\"][duplicate_match_index] += \" || \" + doc1_ents.loc[index1,'Span Text']\n",
    "                result_dict[\"Duplicate Matches?\"][duplicate_match_index] = 1\n",
    "            else:\n",
    "                result_dict[\"Index\"].append(index1)\n",
    "                result_dict[\"Annotation_1\"].append(doc1_ents.loc[index1,'Span Text'])\n",
    "                annot_2 = \"\"\n",
    "                first_time=1\n",
    "                for index2 in sorted(doc1_matches[index1]):\n",
    "                    if first_time ==1:\n",
    "                        annot_2 += doc2_ents.loc[index2,'Span Text']\n",
    "                        first_time=0\n",
    "                    else:\n",
    "                        annot_2 += \" || \" + doc2_ents.loc[index2,'Span Text']\n",
    "                result_dict[\"Annotation_2\"].append(annot_2)\n",
    "                result_dict[\"Exact Match?\"].append(\"\")\n",
    "                if len(doc1_matches[index1]) > 1:\n",
    "                    result_dict[\"Duplicate Matches?\"].append(1)\n",
    "                else:\n",
    "                    result_dict[\"Duplicate Matches?\"].append(0)\n",
    "                result_dict[\"Overlap?\"].append(1)\n",
    "        else:\n",
    "            result_dict[\"Index\"].append(index1)\n",
    "            result_dict[\"Annotation_1\"].append(doc1_ents.loc[index1,'Span Text'])\n",
    "            result_dict[\"Annotation_2\"].append(\"\")\n",
    "            result_dict[\"Exact Match?\"].append(0)\n",
    "            result_dict[\"Duplicate Matches?\"].append(0)\n",
    "            result_dict[\"Overlap?\"].append(0)\n",
    "    for index2 in range(doc2_ents.shape[0]):\n",
    "        if index2 not in doc2_matches.keys():\n",
    "            result_dict[\"Index\"].append(index2)\n",
    "            result_dict[\"Annotation_1\"].append(\"\")\n",
    "            result_dict[\"Annotation_2\"].append(doc1_ents.loc[index2,'Span Text'])\n",
    "            result_dict[\"Exact Match?\"].append(0)\n",
    "            result_dict[\"Duplicate Matches?\"].append(0)\n",
    "            result_dict[\"Overlap?\"].append(0)\n",
    "        #Add annotation2\n",
    "    return pd.DataFrame.from_dict(result_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8]",
   "language": "python",
   "name": "conda-env-python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
