{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb0fb6",
   "metadata": {},
   "source": [
    "# Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ce3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5c733-d512-4bed-b643-cb0a5a01915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add063d2-cb64-451f-8dda-65cc9cd719e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda30c7e-df45-4e2e-b63e-916da8f1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf660-1860-489a-a326-06347f7b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ee93-5f7a-4a34-b610-44467c63c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13836407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run below cells before this\n",
    "tp,fp,fn = agreement(doc,doc2,1,1)\n",
    "print(tp,fp,fn)\n",
    "print(pairwise_f1(tp,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "102f0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66da284",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "test_str = \"This is a test document. For testing lol.\"\n",
    "test_str_2 = \"This is a test document. For testing lol.\"\n",
    "\n",
    "doc = nlp(test_str)\n",
    "doc2 = nlp(test_str)\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[0:1], doc[1:3]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc.spans[\"entity\"] = group\n",
    "\n",
    "\n",
    "spans = [doc2[0:1], doc2[1:5],doc2[4:5]]\n",
    "group = SpanGroup(doc2, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc2.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc2, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc2.spans[\"entity\"] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e55ae52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Error: Input must be iterable of spacy documents, or dataframe.\n"
     ]
    }
   ],
   "source": [
    "IAA.corpus_agreement([doc.spans['errors']],doc.ents,labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4725109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a test', 'PERSON'), ('utah', 'GPE'), ('mississippi', 'PERSON'), ('lake', 'GPE'), ('city', 'GPE')]\n",
      "[utah, or mississippi]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[7:8], doc[8:10]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "print(doc.spans['errors'])\n",
    "print(doc.spans['errors'][0].label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.spans['errors'])\n",
    "for span in doc.spans['errors']:\n",
    "    print('what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5026449",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc.ents,doc.spans['errors'],labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc,doc2,ent_or_span='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc.ents[0]) is spacy.tokens.span.Span\n",
    "type(doc.spans['errors']) is spacy.tokens.span_group.SpanGroup\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098164e2",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def overlaps(doc1_ents, doc2_ents,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        tree.add(ent2.start_char,ent2.end_char,index2)\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        matches = tree.search(ent1.start_char,ent1.end_char)\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (doc2_ents[index2].label_ == ent1.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the old, less efficient code. The newer code uses a tree search instead of the nested for-loop.\n",
    "\n",
    "def old_overlaps(doc1_ents, doc2_ents,labels):\n",
    "    '''Old code for calculating overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        for index2,ent2 in enumerate(doc2_ents):\n",
    "            if (ent1.end_char >= ent2.start_char) & (ent1.start_char <= ent2.end_char) & ((labels==0) | (ent1.label_ == ent2.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(doc1_ents, doc2_ents, labels):\n",
    "    '''calculate whether two ents have exact overlap\n",
    "    returns bool\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    doc1_ent_dict = dict()\n",
    "    doc2_ent_dict = dict()\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        if labels == 1: #If checking for labels, then include this in the tuple's to-be-compared elements\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char,ent1.label_)] = index1\n",
    "        else:\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char)] = index1\n",
    "            \n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        if labels == 1:    \n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char,ent2.label_)] = index2\n",
    "        else:\n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char)] = index2\n",
    "        \n",
    "    doc1_ent_set = set(doc1_ent_dict.keys())\n",
    "    doc2_ent_set = set(doc2_ent_dict.keys())\n",
    "    \n",
    "    matched_ents = doc1_ent_set.intersection(doc2_ent_set)\n",
    "    \n",
    "    for match in matched_ents:\n",
    "        index1 = doc1_ent_dict[match]\n",
    "        index2 = doc2_ent_dict[match]\n",
    "        doc1_matches[index1] = [index2]\n",
    "        doc2_matches[index2] = [index1]\n",
    "        \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, loose=1, labels=1, ent_or_span = 'ent'):\n",
    "    '''Calculates confusion matrix for agreement between two documents.\n",
    "    \n",
    "       returns true positive, false positive, and false negative\n",
    "    '''\n",
    "    if (type(doc1) is tuple) or (type(doc1) is spacy.tokens.span_group.SpanGroup) and \\\n",
    "    (type(doc2) is tuple) or (type(doc2) is spacy.tokens.span_group.SpanGroup):\n",
    "        doc1_ents = doc1\n",
    "        doc2_ents = doc2\n",
    "    elif (type(doc1) is spacy.tokens.doc.Doc) and (type(doc2) is spacy.tokens.doc.Doc):\n",
    "        if ent_or_span == 'ent':\n",
    "            doc1_ents = doc1.ents\n",
    "            doc2_ents = doc2.ents\n",
    "        elif ent_or_span == 'span':\n",
    "            if len(doc1.spans) > 1:\n",
    "                #raise error\n",
    "                print(\"Error: cannot distinquish which span group to use from doc1.\")\n",
    "                return\n",
    "            else:\n",
    "                span_group = list(doc1.spans.keys())[0]\n",
    "                doc1_ents = doc1.spans[span_group]\n",
    "                doc2_ents = doc2.spans[span_group]\n",
    "        else:\n",
    "            #raise error\n",
    "            print(\"Error: Must select 'span' or 'ent' for ent_or_span option.\")\n",
    "            return\n",
    "    else:\n",
    "        #raise error\n",
    "        print(\"Error: Input must be of type 'tuples', 'spacy.tokens.span_group.SpanGroup', or 'spacy.tokens.doc.Doc'\")\n",
    "        return\n",
    "        \n",
    "    if loose:\n",
    "        doc1_matches, doc2_matches = overlaps(doc1_ents, doc2_ents, labels)\n",
    "    else:\n",
    "        doc1_matches, doc2_matches = exact_match(doc1_ents, doc2_ents, labels)\n",
    "    \n",
    "    return conf_matrix(doc1_matches,doc2_matches,len(doc1_ents),len(doc2_ents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(doc1_matches,doc2_matches,doc1_ent_num,doc2_ent_num):\n",
    "\n",
    "    doc1_match_num = len(doc1_matches.keys())\n",
    "    doc2_match_num = len(doc2_matches.keys())\n",
    "    \n",
    "    duplicate_matches = 0\n",
    "    for value in doc2_matches.values():\n",
    "        duplicate_matches += len(value) - 1\n",
    "    \n",
    "    tp = doc1_match_num - duplicate_matches #How many entity indices from doc1 matched, minus duplicated matches\n",
    "    fp = doc2_ent_num - doc2_match_num #How many entities from doc2 that didn't match\n",
    "    fn = doc1_ent_num - doc1_match_num #How many entities from doc1 that didn't match\n",
    "    \n",
    "    return (tp,fp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(tp,fp,fn):\n",
    "    '''calculate f1 given true positive, false positive, and false negative values'''\n",
    "    \n",
    "    return (2*tp)/float(2*tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    if type(docs1[0]) is spacy.tokens.doc.Doc:\n",
    "        for i, doc1 in enumerate(docs1):\n",
    "            tp,fp,fn = agreement(doc1, docs2[i],loose,labels,ent_or_span)\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    elif type(docs1) is pandas.core.frame.DataFrame:\n",
    "        for doc_name in docs1['doc name'].unique():\n",
    "            docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "            docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "            doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "            tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    else:\n",
    "        #raise error\n",
    "        print('Input Error: Input must be iterable of spacy documents, or dataframe.')\n",
    "        return\n",
    "    \n",
    "    data = {'IAA' : [pairwise_f1(corpus_tp,corpus_fp,corpus_fn)], 'Recall' : [tp/float(tp+fp)], 'Precision' : [tp/float(tp+fn)],\\\n",
    "           'True Positives' : [tp] , 'False Positives' : [fp], 'False Negative' : [fn]}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659aa61",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b1907",
   "metadata": {},
   "source": [
    "In this tutorial I will go over the basic, front-end usage of calculating IAA between 2 annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdbe257",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "#Note for John: Get better examples or make my own entities\n",
    "doc1 = nlp1(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "print('doc1.ents: ',doc1.ents)\n",
    "print('doc2.ents: ',doc2.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9bda4",
   "metadata": {},
   "source": [
    "Above we made two documents using spacy's NER packages. Document 2 added more entities than document 1. Let's calculate the IAA between these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_agreement([doc1],[doc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deef70",
   "metadata": {},
   "source": [
    "'corpus_agreement' calculates the agreement between two lists of documents. Note the brackets around 'doc1' and 'doc2' so they are passed in as lists of size 1 each.\n",
    "\n",
    "'corpus_agreement' can also take options to be more flexible with other IAA methods. Below are the arguments:\n",
    "\n",
    "### corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent')\n",
    "\n",
    "docs1: list of spacy documents\n",
    "\n",
    "docs2: list of spacy documents with same order as docs1\n",
    "\n",
    "loose: Boolean for allowing loose matching. '1' indicates that any overlap between two spans/entities is counted towards IAA. '0' indicates that only exact matches will be allowed.\n",
    "\n",
    "labels: Boolean to include labels when matching. Uses the .label_ attribute of entities/spans to access labels.\n",
    "\n",
    "ent_or_span: string of whether spans or entities are being compared. If set to 'ent', code will iterate through doc1.ents and doc2.ents. If set to 'span', code will iterate through the spans within doc1 and doc2's first span group. 'span' only works if doc1 has one span group. This option may be extended to include doc._ .concepts option, or to allow multiple span groups to be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cd59c",
   "metadata": {},
   "source": [
    "Internally, corpus_agreement is calling the 'agreement' and 'pairwise_f1' functions on each pair of document in the lists. We can instead choose to call these functions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efb4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e03665",
   "metadata": {},
   "source": [
    "# Code in Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f79a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "john_df = pd.read_pickle('./df_John.pkl')\n",
    "#john_df = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df = pd.read_pickle('./df_Mengke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c205740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def df_overlaps(docs1_df, docs2_df,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,row2 in docs2_df.iterrows():\n",
    "        tree.add(row2['start loc'],row2['end loc'],index2)\n",
    "    \n",
    "    for index1,row1 in docs1_df.iterrows():\n",
    "        matches = tree.search(row1['start loc'],row1['end loc'])\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (docs2_df.loc[index2,'Concept Label'] == row1['Concept Label'])):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd77ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    for doc_name in docs1['doc name'].unique():\n",
    "        docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "        docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "        doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "        tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "        corpus_tp += tp\n",
    "        corpus_fp += fp\n",
    "        corpus_fn += fn\n",
    "    \n",
    "    print('corpus tp: ',corpus_tp,'\\ncorpus fp: ',corpus_fp,'\\ncorpus fn: ',corpus_fn)\n",
    "    \n",
    "    print(tp)\n",
    "    print(corpus_tp)\n",
    "    \n",
    "    #print(\"Not in doc2 annotations:\\n\")\n",
    "    for index,row in docs1.iterrows():\n",
    "        if (index not in doc2_matches.keys()):\n",
    "            #print(row['Span Text'])\n",
    "            break\n",
    "    \n",
    "    return pairwise_f1(corpus_tp,corpus_fp,corpus_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d477f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_agreement(john_df,mengke_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b296aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "john_df_symptoms = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df_symptoms = mengke_df[mengke_df['Concept Label'] == 'Symptom']\n",
    "\n",
    "df_corpus_agreement(john_df_symptoms,mengke_df_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd201b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_agreement(john_df_symptoms,mengke_df_symptoms,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca3f8f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(john_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6de8125e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# caution: path[0] is reserved for script path (or '' in REPL)\n",
    "sys.path.insert(1, './Integrated_code/')\n",
    "import IAA_ as IAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c02654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "john_df = pd.read_pickle('./df_John.pkl')\n",
    "#john_df = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df = pd.read_pickle('./df_Mengke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ab88610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAA</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.338186</td>\n",
       "      <td>0.532628</td>\n",
       "      <td>0.247744</td>\n",
       "      <td>302</td>\n",
       "      <td>265</td>\n",
       "      <td>917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        IAA    Recall  Precision  True Positives  False Positives  \\\n",
       "0  0.338186  0.532628   0.247744             302              265   \n",
       "\n",
       "   False Negative  \n",
       "0             917  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IAA.corpus_agreement(john_df,mengke_df,loose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c02aeb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Span Text</th>\n",
       "      <th>Concept Label</th>\n",
       "      <th>start loc</th>\n",
       "      <th>end loc</th>\n",
       "      <th>doc name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>respiratory failure</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>103</td>\n",
       "      <td>122</td>\n",
       "      <td>485939.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepsis</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>1171</td>\n",
       "      <td>1177</td>\n",
       "      <td>485939.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>edema</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>4629</td>\n",
       "      <td>4634</td>\n",
       "      <td>485939.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Span Text Concept Label  start loc  end loc    doc name\n",
       "0  respiratory failure       Symptom        103      122  485939.txt\n",
       "1               sepsis       Symptom       1171     1177  485939.txt\n",
       "2                edema       Symptom       4629     4634  485939.txt"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df_doc1 = john_df[john_df['doc name'] == '485939.txt']\n",
    "mengke_df_doc1 = mengke_df[mengke_df['doc name'] == '485939.txt']\n",
    "mengke_df_doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6be92d87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Annotation_1</th>\n",
       "      <th>Annotation_2</th>\n",
       "      <th>Exact Match?</th>\n",
       "      <th>Duplicate Matches?</th>\n",
       "      <th>Overlap?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Chief Complaint:</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Assessment and Plan:</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Transfer from [**Hospital Unit Name 1**] for X...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>72 year old male with COPD, CAD initially\\n   ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>respiratory failure</td>\n",
       "      <td>respiratory failure</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>afib</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>right apical pneumothorax</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>right\\n   middle and lower lobe opacity</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>afib</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Right lower extremity edema</td>\n",
       "      <td>edema</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Left lower extremity\\n   edema</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Rash</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>rash</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>hypoxic respiratory failure</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Hypoxic Respiratory Failure</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Pneumothorax</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>DELIRIUM</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>CONFUSION</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>ATRIAL FIBRILLATION</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>PLEURAL EFFUSION</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Assessment and Plan:</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index                                       Annotation_1  \\\n",
       "0       0                                   Chief Complaint:   \n",
       "1       1                               Assessment and Plan:   \n",
       "2       2  Transfer from [**Hospital Unit Name 1**] for X...   \n",
       "3       3  72 year old male with COPD, CAD initially\\n   ...   \n",
       "4       4                                respiratory failure   \n",
       "5       5                                               afib   \n",
       "6       6                          right apical pneumothorax   \n",
       "7       7            right\\n   middle and lower lobe opacity   \n",
       "8       8                                               afib   \n",
       "9       9                        Right lower extremity edema   \n",
       "10     10                     Left lower extremity\\n   edema   \n",
       "11     11                                               Rash   \n",
       "12     12                                               rash   \n",
       "13     13                        hypoxic respiratory failure   \n",
       "14     14                        Hypoxic Respiratory Failure   \n",
       "15     15                                       Pneumothorax   \n",
       "16     16                                           DELIRIUM   \n",
       "17     17                                          CONFUSION   \n",
       "18     18                                ATRIAL FIBRILLATION   \n",
       "19     19                                   PLEURAL EFFUSION   \n",
       "20      1                                                      \n",
       "\n",
       "            Annotation_2 Exact Match?  Duplicate Matches?  Overlap?  \n",
       "0                                   0                   0         0  \n",
       "1                                   0                   0         0  \n",
       "2                                   0                   0         0  \n",
       "3                                   0                   0         0  \n",
       "4    respiratory failure                                0         1  \n",
       "5                                   0                   0         0  \n",
       "6                                   0                   0         0  \n",
       "7                                   0                   0         0  \n",
       "8                                   0                   0         0  \n",
       "9                  edema                                0         1  \n",
       "10                                  0                   0         0  \n",
       "11                                  0                   0         0  \n",
       "12                                  0                   0         0  \n",
       "13                                  0                   0         0  \n",
       "14                                  0                   0         0  \n",
       "15                                  0                   0         0  \n",
       "16                                  0                   0         0  \n",
       "17                                  0                   0         0  \n",
       "18                                  0                   0         0  \n",
       "19                                  0                   0         0  \n",
       "20  Assessment and Plan:            0                   0         0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dicts = IAA.df_overlaps(john_df_doc1,mengke_df_doc1)\n",
    "create_agreement_df(dicts[0],dicts[1],john_df_doc1,mengke_df_doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21e453df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Test1': [6, 5, 6]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict = {\"Test1\" : [4,5,6]}\n",
    "test_dict[\"Test1\"][0] += 2\n",
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0a7ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##This was a very bad idea\n",
    "\n",
    "def match_indices_recursive(doc1_matches,doc2_matches,index,doc1_doc2,doc1_indices,doc2_indices):  \n",
    "    if (doc1_doc2==1):\n",
    "        doc1_indices.add(index)\n",
    "        for index2 in doc1_matches[index]:\n",
    "            if index2 not in doc2_indices():\n",
    "                doc2_indices.add(index2)\n",
    "                doc2_indices.add(match_indices_recursive(doc1_matches,doc2_matches,index2,2,doc1_indices,doc2_indices))\n",
    "    elif doc1_doc2==2:\n",
    "        doc2_indices.add(index)\n",
    "        for index1 in doc2_matches[index]:\n",
    "            return (match_indices_recursive(doc1_matches,doc2_matches,index2,1,doc1_indices,doc2_indices)[0].add(index1))\n",
    "    else:\n",
    "        return [set(),set()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d46b872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agreement_df(doc1_matches,doc2_matches,doc1_ents,doc2_ents):\n",
    "    result_dict = {\"Index\" : [],\"Annotation_1\" : [],\"Annotation_2\" : [], \"Exact Match?\" : [], \"Duplicate Matches?\" : [], \"Overlap?\" : []}\n",
    "    for index1 in range(doc1_ents.shape[0]): #iterate through all ents inset one\n",
    "        if index1 in doc1_matches.keys(): #if ent is in\n",
    "            #if another index1 is in doc2_matches.values(), then add it to this row\n",
    "            first_index2 = sorted(doc1_matches[index1])[0]\n",
    "            first_index1 = sorted(doc2_matches[first_index2])[0]\n",
    "            if first_index1 < index1:\n",
    "                #Add to index: sorted(doc2_matches[first_index2])[0]\n",
    "                duplicate_match_index = result_dict[\"Index\"].index(first_index1)\n",
    "                result_dict[\"Index\"][duplicate_match_index] += \" || \" + doc1_ents.loc[index1,'Span Text']\n",
    "                result_dict[\"Duplicate Matches?\"][duplicate_match_index] = 1\n",
    "            else:\n",
    "                result_dict[\"Index\"].append(index1)\n",
    "                result_dict[\"Annotation_1\"].append(doc1_ents.loc[index1,'Span Text'])\n",
    "                annot_2 = \"\"\n",
    "                first_time=1\n",
    "                for index2 in sorted(doc1_matches[index1]):\n",
    "                    if first_time ==1:\n",
    "                        annot_2 += doc2_ents.loc[index2,'Span Text']\n",
    "                        first_time=0\n",
    "                    else:\n",
    "                        annot_2 += \" || \" + doc2_ents.loc[index2,'Span Text']\n",
    "                result_dict[\"Annotation_2\"].append(annot_2)\n",
    "                result_dict[\"Exact Match?\"].append(\"\")\n",
    "                if len(doc1_matches[index1]) > 1:\n",
    "                    result_dict[\"Duplicate Matches?\"].append(1)\n",
    "                else:\n",
    "                    result_dict[\"Duplicate Matches?\"].append(0)\n",
    "                result_dict[\"Overlap?\"].append(1)\n",
    "        else:\n",
    "            result_dict[\"Index\"].append(index1)\n",
    "            result_dict[\"Annotation_1\"].append(doc1_ents.loc[index1,'Span Text'])\n",
    "            result_dict[\"Annotation_2\"].append(\"\")\n",
    "            result_dict[\"Exact Match?\"].append(0)\n",
    "            result_dict[\"Duplicate Matches?\"].append(0)\n",
    "            result_dict[\"Overlap?\"].append(0)\n",
    "    for index2 in range(doc2_ents.shape[0]):\n",
    "        if index2 not in doc2_matches.keys():\n",
    "            result_dict[\"Index\"].append(index2)\n",
    "            result_dict[\"Annotation_1\"].append(\"\")\n",
    "            result_dict[\"Annotation_2\"].append(doc1_ents.loc[index2,'Span Text'])\n",
    "            result_dict[\"Exact Match?\"].append(0)\n",
    "            result_dict[\"Duplicate Matches?\"].append(0)\n",
    "            result_dict[\"Overlap?\"].append(0)\n",
    "        #Add annotation2\n",
    "    return pd.DataFrame.from_dict(result_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8]",
   "language": "python",
   "name": "conda-env-python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
