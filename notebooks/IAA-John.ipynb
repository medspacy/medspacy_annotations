{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb0fb6",
   "metadata": {},
   "source": [
    "# Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ce3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5c733-d512-4bed-b643-cb0a5a01915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add063d2-cb64-451f-8dda-65cc9cd719e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda30c7e-df45-4e2e-b63e-916da8f1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aaf660-1860-489a-a326-06347f7b78d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ee93-5f7a-4a34-b610-44467c63c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13836407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run below cells before this\n",
    "tp,fp,fn = agreement(doc,doc2,1,1)\n",
    "print(tp,fp,fn)\n",
    "print(pairwise_f1(tp,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102f0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66da284",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "test_str = \"This is a test document. For testing lol.\"\n",
    "test_str_2 = \"This is a test document. For testing lol.\"\n",
    "\n",
    "doc = nlp(test_str)\n",
    "doc2 = nlp(test_str)\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[0:1], doc[1:3]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc.spans[\"entity\"] = group\n",
    "\n",
    "\n",
    "spans = [doc2[0:1], doc2[1:5],doc2[4:5]]\n",
    "group = SpanGroup(doc2, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc2.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc2, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc2.spans[\"entity\"] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4725109",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[7:8], doc[8:10]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "print(doc.spans['errors'])\n",
    "print(doc.spans['errors'][0].label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31a8269",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.spans['errors'])\n",
    "for span in doc.spans['errors']:\n",
    "    print('what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5026449",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc.ents,doc.spans['errors'],labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb1dc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "agreement(doc,doc2,ent_or_span='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41f7c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc.ents[0]) is spacy.tokens.span.Span\n",
    "type(doc.spans['errors']) is spacy.tokens.span_group.SpanGroup\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098164e2",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f8afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def overlaps(doc1_ents, doc2_ents,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        tree.add(ent2.start_char,ent2.end_char,index2)\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        matches = tree.search(ent1.start_char,ent1.end_char)\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (doc2_ents[index2].label_ == ent1.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the old, less efficient code. The newer code uses a tree search instead of the nested for-loop.\n",
    "\n",
    "def old_overlaps(doc1_ents, doc2_ents,labels):\n",
    "    '''Old code for calculating overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        for index2,ent2 in enumerate(doc2_ents):\n",
    "            if (ent1.end_char >= ent2.start_char) & (ent1.start_char <= ent2.end_char) & ((labels==0) | (ent1.label_ == ent2.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(doc1_ents, doc2_ents, labels):\n",
    "    '''calculate whether two ents have exact overlap\n",
    "    returns bool\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    doc1_ent_dict = dict()\n",
    "    doc2_ent_dict = dict()\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        if labels == 1: #If checking for labels, then include this in the tuple's to-be-compared elements\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char,ent1.label_)] = index1\n",
    "        else:\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char)] = index1\n",
    "            \n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        if labels == 1:    \n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char,ent2.label_)] = index2\n",
    "        else:\n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char)] = index2\n",
    "        \n",
    "    doc1_ent_set = set(doc1_ent_dict.keys())\n",
    "    doc2_ent_set = set(doc2_ent_dict.keys())\n",
    "    \n",
    "    matched_ents = doc1_ent_set.intersection(doc2_ent_set)\n",
    "    \n",
    "    for match in matched_ents:\n",
    "        index1 = doc1_ent_dict[match]\n",
    "        index2 = doc2_ent_dict[match]\n",
    "        doc1_matches[index1] = [index2]\n",
    "        doc2_matches[index2] = [index1]\n",
    "        \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, loose=1, labels=1, ent_or_span = 'ent'):\n",
    "    '''Calculates confusion matrix for agreement between two documents.\n",
    "    \n",
    "       returns true positive, false positive, and false negative\n",
    "    '''\n",
    "    if (type(doc1) is tuple) or (type(doc1) is spacy.tokens.span_group.SpanGroup) and \\\n",
    "    (type(doc2) is tuple) or (type(doc2) is spacy.tokens.span_group.SpanGroup):\n",
    "        doc1_ents = doc1\n",
    "        doc2_ents = doc2\n",
    "    elif (type(doc1) is spacy.tokens.doc.Doc) and (type(doc2) is spacy.tokens.doc.Doc):\n",
    "        if ent_or_span == 'ent':\n",
    "            doc1_ents = doc1.ents\n",
    "            doc2_ents = doc2.ents\n",
    "        elif ent_or_span == 'span':\n",
    "            if len(doc1.spans) > 1:\n",
    "                #raise error\n",
    "                print(\"Error: cannot distinquish which span group to use from doc1.\")\n",
    "                return\n",
    "            else:\n",
    "                span_group = list(doc1.spans.keys())[0]\n",
    "                doc1_ents = doc1.spans[span_group]\n",
    "                doc2_ents = doc2.spans[span_group]\n",
    "        else:\n",
    "            #raise error\n",
    "            print(\"Error: Must select 'span' or 'ent' for ent_or_span option.\")\n",
    "            return\n",
    "    else:\n",
    "        #raise error\n",
    "        print(\"Error: Input must be of type 'tuples', 'spacy.tokens.span_group.SpanGroup', or 'spacy.tokens.doc.Doc'\")\n",
    "        return\n",
    "        \n",
    "    if loose:\n",
    "        doc1_matches, doc2_matches = overlaps(doc1_ents, doc2_ents, labels)\n",
    "    else:\n",
    "        doc1_matches, doc2_matches = exact_match(doc1_ents, doc2_ents, labels)\n",
    "    \n",
    "    return conf_matrix(doc1_matches,doc2_matches,len(doc1_ents),len(doc2_ents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b01c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(doc1_matches,doc2_matches,doc1_ent_num,doc2_ent_num):\n",
    "\n",
    "    doc1_match_num = len(doc1_matches.keys())\n",
    "    doc2_match_num = len(doc2_matches.keys())\n",
    "    \n",
    "    duplicate_matches = 0\n",
    "    for value in doc2_matches.values():\n",
    "        duplicate_matches += len(value) - 1\n",
    "    \n",
    "    tp = doc1_match_num - duplicate_matches #How many entity indices from doc1 matched, minus duplicated matches\n",
    "    fp = doc2_ent_num - doc2_match_num #How many entities from doc2 that didn't match\n",
    "    fn = doc1_ent_num - doc1_match_num #How many entities from doc1 that didn't match\n",
    "    \n",
    "    return (tp,fp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(tp,fp,fn):\n",
    "    '''calculate f1 given true positive, false positive, and false negative values'''\n",
    "    \n",
    "    return (2*tp)/float(2*tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    if type(docs1[0]) is spacy.tokens.doc.Doc:\n",
    "        for i, doc1 in enumerate(docs1):\n",
    "            tp,fp,fn = agreement(doc1, docs2[i],loose,labels,ent_or_span)\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    elif type(docs1) is pandas.core.frame.DataFrame:\n",
    "        for doc_name in docs1['doc name'].unique():\n",
    "            docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "            docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "            doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "            tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "            corpus_tp += tp\n",
    "            corpus_fp += fp\n",
    "            corpus_fn += fn\n",
    "    else:\n",
    "        #raise error\n",
    "        print('Input Error: Input must be iterable of spacy documents, or dataframe.')\n",
    "        return\n",
    "    \n",
    "    data = {'IAA' : [pairwise_f1(corpus_tp,corpus_fp,corpus_fn)], 'Recall' : [tp/float(tp+fp)], 'Precision' : [tp/float(tp+fn)],\\\n",
    "           'True Positives' : [tp] , 'False Positives' : [fp], 'False Negative' : [fn]}\n",
    "    \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f659aa61",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36b1907",
   "metadata": {},
   "source": [
    "In this tutorial I will go over the basic, front-end usage of calculating IAA between 2 annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4bdbe257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1.ents:  (utah, mississippi)\n",
      "doc2.ents:  (utah, mississippi, lake city)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "#Note for John: Get better examples or make my own entities\n",
    "doc1 = nlp1(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "print('doc1.ents: ',doc1.ents)\n",
    "print('doc2.ents: ',doc2.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9bda4",
   "metadata": {},
   "source": [
    "Above we made two documents using spacy's NER packages. Document 2 added more entities than document 1. Let's calculate the IAA between these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b51f033b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAA</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>True Positives</th>\n",
       "      <th>False Positives</th>\n",
       "      <th>False Negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IAA    Recall  Precision  True Positives  False Positives  False Negative\n",
       "0  0.8  0.666667        1.0               2                1               0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_agreement([doc1],[doc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67deef70",
   "metadata": {},
   "source": [
    "'corpus_agreement' calculates the agreement between two lists of documents. Note the brackets around 'doc1' and 'doc2' so they are passed in as lists of size 1 each.\n",
    "\n",
    "'corpus_agreement' can also take options to be more flexible with other IAA methods. Below are the arguments:\n",
    "\n",
    "### corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent')\n",
    "\n",
    "docs1: list of spacy documents\n",
    "\n",
    "docs2: list of spacy documents with same order as docs1\n",
    "\n",
    "loose: Boolean for allowing loose matching. '1' indicates that any overlap between two spans/entities is counted towards IAA. '0' indicates that only exact matches will be allowed.\n",
    "\n",
    "labels: Boolean to include labels when matching. Uses the .label_ attribute of entities/spans to access labels.\n",
    "\n",
    "ent_or_span: string of whether spans or entities are being compared. If set to 'ent', code will iterate through doc1.ents and doc2.ents. If set to 'span', code will iterate through the spans within doc1 and doc2's first span group. 'span' only works if doc1 has one span group. This option may be extended to include doc._ .concepts option, or to allow multiple span groups to be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41cd59c",
   "metadata": {},
   "source": [
    "Internally, corpus_agreement is calling the 'agreement' and 'pairwise_f1' functions on each pair of document in the lists. We can instead choose to call these functions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96efb4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71e03665",
   "metadata": {},
   "source": [
    "# Code in Development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f79a678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "john_df = pd.read_pickle('./df_John.pkl')\n",
    "#john_df = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df = pd.read_pickle('./df_Mengke.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c205740",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def df_overlaps(docs1_df, docs2_df,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,row2 in docs2_df.iterrows():\n",
    "        tree.add(row2['start loc'],row2['end loc'],index2)\n",
    "    \n",
    "    for index1,row1 in docs1_df.iterrows():\n",
    "        matches = tree.search(row1['start loc'],row1['end loc'])\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (docs2_df.loc[index2,'Concept Label'] == row1['Concept Label'])):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dd77ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    for doc_name in docs1['doc name'].unique():\n",
    "        docs1_df = docs1[docs1['doc name'] == doc_name]\n",
    "        docs2_df = docs2[docs2['doc name'] == doc_name]\n",
    "        doc1_matches,doc2_matches = df_overlaps(docs1_df,docs2_df)\n",
    "        tp,fp,fn = conf_matrix(doc1_matches,doc2_matches,docs1_df.shape[0],docs2_df.shape[0])\n",
    "        corpus_tp += tp\n",
    "        corpus_fp += fp\n",
    "        corpus_fn += fn\n",
    "    \n",
    "    print('corpus tp: ',corpus_tp,'\\ncorpus fp: ',corpus_fp,'\\ncorpus fn: ',corpus_fn)\n",
    "    \n",
    "    print(tp)\n",
    "    print(corpus_tp)\n",
    "    \n",
    "    #print(\"Not in doc2 annotations:\\n\")\n",
    "    for index,row in docs1.iterrows():\n",
    "        if (index not in doc2_matches.keys()):\n",
    "            #print(row['Span Text'])\n",
    "            break\n",
    "    \n",
    "    return pairwise_f1(corpus_tp,corpus_fp,corpus_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d477f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus tp:  376 \n",
      "corpus fp:  176 \n",
      "corpus fn:  842\n",
      "8\n",
      "376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4248587570621469"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus_agreement(john_df,mengke_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37b296aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus tp:  348 \n",
      "corpus fp:  157 \n",
      "corpus fn:  563\n",
      "8\n",
      "348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4915254237288136"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "john_df_symptoms = john_df[john_df['Concept Label'] == 'Symptom']\n",
    "mengke_df_symptoms = mengke_df[mengke_df['Concept Label'] == 'Symptom']\n",
    "\n",
    "df_corpus_agreement(john_df_symptoms,mengke_df_symptoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bd201b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.8\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [55]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcorpus_agreement\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjohn_df_symptoms\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmengke_df_symptoms\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36mcorpus_agreement\u001b[1;34m(docs1, docs2, loose, labels, ent_or_span)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m'''calculate f1 over an entire corpus of documents'''\u001b[39;00m\n\u001b[0;32m      3\u001b[0m corpus_tp, corpus_fp, corpus_fn \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[43mdocs1\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m spacy\u001b[38;5;241m.\u001b[39mtokens\u001b[38;5;241m.\u001b[39mdoc\u001b[38;5;241m.\u001b[39mDoc:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, doc1 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(docs1):\n\u001b[0;32m      7\u001b[0m         tp,fp,fn \u001b[38;5;241m=\u001b[39m agreement(doc1, docs2[i],loose,labels,ent_or_span)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.8\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\python3.8\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "corpus_agreement(john_df_symptoms,mengke_df_symptoms,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "aca3f8f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(john_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8]",
   "language": "python",
   "name": "conda-env-python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
