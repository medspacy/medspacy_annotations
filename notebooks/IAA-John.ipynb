{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a6946d4-c620-46fa-829e-4cb7c0bf56ec",
   "metadata": {},
   "source": [
    "# Spacy/Medspacy IAA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf1275d-aea3-42ff-bb49-a70af27e8724",
   "metadata": {},
   "source": [
    "## Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4767b5a-d4ea-472a-b95b-224a5f3ac8fd",
   "metadata": {},
   "source": [
    "Prodigy forum answer about IAA for spans https://support.prodi.gy/t/proper-way-to-calculate-inter-annotator-agreement-for-spans-ner/5760\n",
    "\n",
    "Spacy scorer object https://spacy.io/api/scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ae97f4-619f-4f09-8e87-767767b5830b",
   "metadata": {},
   "source": [
    "## End Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759cea6f-2684-4b0b-bb00-f8541df72e6b",
   "metadata": {},
   "source": [
    "### Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aa04fb-5095-4672-b315-43791d53fcca",
   "metadata": {},
   "source": [
    "Provide a collection of methods to evaluate IAA between _n_ arbitrary spacy `doc` objects. Provide methods that aid in error analysis such as providing lists of differences.\n",
    "\n",
    "Priorities:\n",
    "* Pairwise F1\n",
    "    * configurable strict/loose matching\n",
    "    * configurable inclusion of labels/attributes (calculate just span vs span+class agreement)\n",
    "\n",
    "* Imported python files\n",
    "    * reasonable docstrings on methods/classes\n",
    "    \n",
    "* Unit tests\n",
    "    * add CI to repo for automated testing later\n",
    "\n",
    "Extra features:\n",
    "* List of differences between docs\n",
    "* \n",
    "\n",
    "Expected challenges\n",
    "* Spacy scorer functions are useful, but _only_ do strict span matching\n",
    "* Fewer resources (obviously?) available for comparisons between 3+ docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb0fb6",
   "metadata": {},
   "source": [
    "# Testing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07738af3-f6f3-4868-be7b-69258b0ec3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2ce3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea5c733-d512-4bed-b643-cb0a5a01915c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919e2eea-0032-4232-95a8-a57085cb3310",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add063d2-cb64-451f-8dda-65cc9cd719e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bda30c7e-df45-4e2e-b63e-916da8f1ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20aaf660-1860-489a-a326-06347f7b78d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(utah, mississippi, lake city)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ecb69f-9a0e-4930-ab72-36dea261fea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed28ee93-5f7a-4a34-b610-44467c63c92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Span\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "# Print entities' text and labels\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13836407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run below cells before this\n",
    "tp,fp,fn = agreement(doc,doc2,1,1)\n",
    "print(tp,fp,fn)\n",
    "print(pairwise_f1(tp,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a4ef92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "102f0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b66da284",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "test_str = \"This is a test document. For testing lol.\"\n",
    "test_str_2 = \"This is a test document. For testing lol.\"\n",
    "\n",
    "doc = nlp(test_str)\n",
    "doc2 = nlp(test_str)\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[0:1], doc[1:3]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc.spans[\"entity\"] = group\n",
    "\n",
    "\n",
    "spans = [doc2[0:1], doc2[1:5],doc2[4:5]]\n",
    "group = SpanGroup(doc2, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc2.spans[\"errors\"] = group\n",
    "group = SpanGroup(doc2, name=\"entity1\", spans=spans, attrs={\"annotator\": \"John\"})\n",
    "#doc2.spans[\"entity\"] = group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4725109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('a test', 'PERSON'), ('utah', 'GPE'), ('mississippi', 'PERSON'), ('lake', 'GPE'), ('city', 'GPE')]\n",
      "[utah, or mississippi]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Span\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "spand = list()\n",
    "spand += [Span(doc, 2, 4, label=\"PERSON\"),Span(doc,7,8,label=\"GPE\"),Span(doc,9,10,label=\"PERSON\"),Span(doc,13,14,label=\"GPE\"),Span(doc,14,15,label=\"GPE\")]\n",
    "\n",
    "# Add the span to the doc's entities\n",
    "doc.ents = spand\n",
    "\n",
    "print([(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "from spacy.tokens import SpanGroup\n",
    "\n",
    "spans = [doc[7:8], doc[8:10]]\n",
    "group = SpanGroup(doc, name=\"errors\", spans=spans, attrs={\"annotator\": \"matt\"})\n",
    "doc.spans[\"errors\"] = group\n",
    "print(doc.spans['errors'])\n",
    "print(doc.spans['errors'][0].label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f31a8269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[utah, or mississippi]\n",
      "what\n",
      "what\n"
     ]
    }
   ],
   "source": [
    "print(doc.spans['errors'])\n",
    "for span in doc.spans['errors']:\n",
    "    print('what')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5026449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement(doc.ents,doc.spans['errors'],labels=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ebb1dc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 5)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agreement(doc,doc2,ent_or_span='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f41f7c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc.ents[0]) is spacy.tokens.span.Span\n",
    "type(doc.spans['errors']) is spacy.tokens.span_group.SpanGroup\n",
    "\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098164e2",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f8afd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quicksectx import IntervalNode, IntervalTree, Interval #note that you need the quicksectx library\n",
    "\n",
    "#In order to make the code a little more adaptable for situations of multiple overlapping entities, as well as for \n",
    "#transparency and testing the code, I wrote the overlaps code to output a mapping of which entities are being matched. \n",
    "#Then agreement can parse this output for how many valid overlaps exist.\n",
    "\n",
    "#This makes the code a little more complicated to understand, but I think it makes everything more transparent and adaptable.\n",
    "\n",
    "def overlaps(doc1_ents, doc2_ents,labels=1):\n",
    "    '''Calculates overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "    \n",
    "    tree = IntervalTree()\n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        tree.add(ent2.start_char,ent2.end_char,index2)\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        matches = tree.search(ent1.start_char,ent1.end_char)\n",
    "        for match in matches:\n",
    "            index2 = match.data #match.data is the index of doc2_ents\n",
    "            if ((labels == 0) | (doc2_ents[index2].label_ == ent1.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b138a1-a375-4503-93fd-76cf9e2721b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the old, less efficient code. The newer code uses a tree search instead of the nested for-loop.\n",
    "\n",
    "def old_overlaps(doc1_ents, doc2_ents,labels):\n",
    "    '''Old code for calculating overlapping entities between two spacy documents. Also checks for matching labels if label=1.\n",
    "    \n",
    "    Return:\n",
    "        Dictionaries with the mapping of matching entity indices:\n",
    "            keys: entity index from one annotation\n",
    "            value: matched entity index from other annotation\n",
    "        \n",
    "        Ex: \"{1 : [2] , 3 : [4,5]}\" means that entity 1 from doc1 matches entity 1 in doc2, and entity 3 in doc1 matches \n",
    "        entity 4 and 5 from doc2.\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        for index2,ent2 in enumerate(doc2_ents):\n",
    "            if (ent1.end_char >= ent2.start_char) & (ent1.start_char <= ent2.end_char) & ((labels==0) | (ent1.label_ == ent2.label_)):\n",
    "                if index1 not in doc1_matches.keys():\n",
    "                    doc1_matches[index1] = [index2]\n",
    "                else:\n",
    "                    doc1_matches[index1].append(index2)\n",
    "                if index2 not in doc2_matches.keys():\n",
    "                    doc2_matches[index2] = [index1]\n",
    "                else:\n",
    "                    doc2_matches[index2].append(index1)\n",
    "                \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00a8e6a7-7116-405c-addd-b19e08a9fae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exact_match(doc1_ents, doc2_ents, labels):\n",
    "    '''calculate whether two ents have exact overlap\n",
    "    returns bool\n",
    "    '''\n",
    "    \n",
    "    doc1_matches = dict()\n",
    "    doc2_matches = dict()\n",
    "\n",
    "    doc1_ent_dict = dict()\n",
    "    doc2_ent_dict = dict()\n",
    "    \n",
    "    for index1,ent1 in enumerate(doc1_ents):\n",
    "        if labels == 1: #If checking for labels, then include this in the tuple's to-be-compared elements\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char,ent1.label_)] = index1\n",
    "        else:\n",
    "            doc1_ent_dict[(ent1.start_char,ent1.end_char)] = index1\n",
    "            \n",
    "    for index2,ent2 in enumerate(doc2_ents):\n",
    "        if labels == 1:    \n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char,ent2.label_)] = index2\n",
    "        else:\n",
    "            doc2_ent_dict[(ent2.start_char,ent2.end_char)] = index2\n",
    "        \n",
    "    doc1_ent_set = set(doc1_ent_dict.keys())\n",
    "    doc2_ent_set = set(doc2_ent_dict.keys())\n",
    "    \n",
    "    matched_ents = doc1_ent_set.intersection(doc2_ent_set)\n",
    "    \n",
    "    for match in matched_ents:\n",
    "        index1 = doc1_ent_dict[match]\n",
    "        index2 = doc2_ent_dict[match]\n",
    "        doc1_matches[index1] = [index2]\n",
    "        doc2_matches[index2] = [index1]\n",
    "        \n",
    "    return doc1_matches, doc2_matches\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "650bc405-f61d-4287-ac88-14ed6072bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agreement(doc1, doc2, loose=1, labels=1, ent_or_span = 'ent'):\n",
    "    '''Calculates confusion matrix for agreement between two documents.\n",
    "    \n",
    "       returns true positive, false positive, and false negative\n",
    "    '''\n",
    "    if (type(doc1) is tuple) or (type(doc1) is spacy.tokens.span_group.SpanGroup) and \\\n",
    "    (type(doc2) is tuple) or (type(doc2) is spacy.tokens.span_group.SpanGroup):\n",
    "        doc1_ents = doc1\n",
    "        doc2_ents = doc2\n",
    "    elif (type(doc1) is spacy.tokens.doc.Doc) and (type(doc2) is spacy.tokens.doc.Doc):\n",
    "        if ent_or_span == 'ent':\n",
    "            doc1_ents = doc1.ents\n",
    "            doc2_ents = doc2.ents\n",
    "        elif ent_or_span == 'span':\n",
    "            if len(doc1.spans) > 1:\n",
    "                #raise error\n",
    "                print(\"Error: cannot distinquish which span group to use from doc1.\")\n",
    "                return\n",
    "            else:\n",
    "                span_group = list(doc1.spans.keys())[0]\n",
    "                doc1_ents = doc1.spans[span_group]\n",
    "                doc2_ents = doc2.spans[span_group]\n",
    "        else:\n",
    "            #raise error\n",
    "            print(\"Error: Must select 'span' or 'ent' for ent_or_span option.\")\n",
    "            return\n",
    "    else:\n",
    "        #raise error\n",
    "        print(\"Error: Input must be of type 'tuples', 'spacy.tokens.span_group.SpanGroup', or 'spacy.tokens.doc.Doc'\")\n",
    "        return\n",
    "        \n",
    "    if loose:\n",
    "        doc1_matches, doc2_matches = overlaps(doc1_ents, doc2_ents, labels)\n",
    "    else:\n",
    "        doc1_matches, doc2_matches = exact_match(doc1_ents, doc2_ents, labels)\n",
    "    \n",
    "    return conf_matrix(doc1_matches,doc2_matches,len(doc1_ents),len(doc2_ents))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b01c45b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_matrix(doc1_matches,doc2_matches,doc1_ent_num,doc2_ent_num):\n",
    "\n",
    "    doc1_match_num = len(doc1_matches.keys())\n",
    "    doc2_match_num = len(doc2_matches.keys())\n",
    "    \n",
    "    duplicate_matches = 0\n",
    "    for value in doc2_matches.values():\n",
    "        duplicate_matches += len(value) - 1\n",
    "    \n",
    "    tp = doc1_match_num - duplicate_matches #How many entity indices from doc1 matched, minus duplicated matches\n",
    "    fp = doc2_ent_num - doc2_match_num #How many entities from doc2 that didn't match\n",
    "    fn = doc1_ent_num - doc1_match_num #How many entities from doc1 that didn't match\n",
    "    \n",
    "    return (tp,fp,fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b609c982-0b94-4913-b23b-a672950bd99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_f1(tp,fp,fn):\n",
    "    '''calculate f1 given true positive, false positive, and false negative values'''\n",
    "    \n",
    "    return (2*tp)/float(2*tp+fp+fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0b3a52c-8d6b-4a15-a7ae-5fc992f4564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent'):\n",
    "    '''calculate f1 over an entire corpus of documents'''\n",
    "    corpus_tp, corpus_fp, corpus_fn = (0,0,0)\n",
    "    \n",
    "    for i, doc1 in enumerate(docs1):\n",
    "        tp,fp,fn = agreement(doc1, docs2[i],loose,labels,ent_or_span)\n",
    "        corpus_tp += tp\n",
    "        corpus_fp += fp\n",
    "        corpus_fn += fn\n",
    "    \n",
    "    \n",
    "    return pairwise_f1(tp,fp,fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f830f821",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fdc230",
   "metadata": {},
   "source": [
    "In this tutorial I will go over the basic, front-end usage of calculating IAA between 2 annotators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2b71c3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1.ents:  (utah, mississippi)\n",
      "doc2.ents:  (utah, mississippi, lake city)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp1 = spacy.load(\"en_core_web_sm\")\n",
    "nlp2 = spacy.load(\"en_core_web_md\")\n",
    "#!python -m spacy download en_core_web_sm\n",
    "#!python -m spacy download en_core_web_md\n",
    "\n",
    "#Note for John: Get better examples or make my own entities\n",
    "doc1 = nlp1(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "doc2 = nlp2(\"this is a test document made in utah or mississippi, or salt lake city.\")\n",
    "\n",
    "print('doc1.ents: ',doc1.ents)\n",
    "print('doc2.ents: ',doc2.ents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf67766",
   "metadata": {},
   "source": [
    "Above we made two documents using spacy's NER packages. Document 2 added more entities than document 1. Let's calculate the IAA between these documents!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2da909d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_agreement([doc1],[doc2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8da40f",
   "metadata": {},
   "source": [
    "'corpus_agreement' calculates the agreement between two lists of documents. Note the brackets around 'doc1' and 'doc2' so they are passed in as lists of size 1 each.\n",
    "\n",
    "'corpus_agreement' can also take options to be more flexible with other IAA methods. Below are the arguments:\n",
    "\n",
    "### corpus_agreement(docs1, docs2, loose=1, labels=1,ent_or_span='ent')\n",
    "\n",
    "docs1: list of spacy documents\n",
    "\n",
    "docs2: list of spacy documents with same order as docs1\n",
    "\n",
    "loose: Boolean for allowing loose matching. '1' indicates that any overlap between two spans/entities is counted towards IAA. '0' indicates that only exact matches will be allowed.\n",
    "\n",
    "labels: Boolean to include labels when matching. Uses the .label_ attribute of entities/spans to access labels.\n",
    "\n",
    "ent_or_span: string of whether spans or entities are being compared. If set to 'ent', code will iterate through doc1.ents and doc2.ents. If set to 'span', code will iterate through the spans within doc1 and doc2's first span group. 'span' only works if doc1 has one span group. This option may be extended to include doc._ .concepts option, or to allow multiple span groups to be compared."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0644cbe2",
   "metadata": {},
   "source": [
    "Internally, corpus_agreement is calling the 'agreement' and 'pairwise_f1' functions on each pair of document in the lists. We can instead choose to call these functions separate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "44ad2c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.8]",
   "language": "python",
   "name": "conda-env-python3.8-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
